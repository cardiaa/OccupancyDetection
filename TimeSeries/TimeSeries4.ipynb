{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from keras.optimizers import Adagrad\n",
    "from tslearn.shapelets import ShapeletModel\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# crea un dataset orario\n",
    "def build_dataset(df, attribute, class_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in [3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17]:\n",
    "        day = df.loc[df['day'] == d]\n",
    "        for h in range(0, 24):\n",
    "            hour = day.loc[day['hour'] == h]\n",
    "            X.append(hour[attribute].values)\n",
    "            y.append(1 if hour[class_name].mean() >= 0.50 else 0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un dataset di 6 ore\n",
    "def build_dataset(df, attribute, class_name):\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in [3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17]:\n",
    "        day = df.loc[df['day'] == d]\n",
    "        for h in range(0, 4):\n",
    "            if h != 0:\n",
    "                hour = day.loc[(day['hour'] >= h * 6) & (day['hour'] < (h+1) * 6)]\n",
    "            else:\n",
    "                hour = day.loc[day['hour'] <= 5]\n",
    "            X.append(hour[attribute].values)\n",
    "            y.append(1 if hour[class_name].mean() >= 0.50 else 0)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 360)\n",
      "[0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df = pd.read_csv('dataset.csv', parse_dates= True, index_col='date', date_parser=dateparse)\n",
    "\n",
    "X, y = build_dataset(df, 'CO2', 'Occupancy')\n",
    "print(X.shape)\n",
    "print(y)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def create_time_index(df):\n",
    "    df = df.reset_index() # con indice numerico possiamo interare lungo il df normalmente\n",
    "    #create the new index\n",
    "    time=[]\n",
    "    for i in df.index:\n",
    "        h = df.loc[i]['hour']\n",
    "        m = df.loc[i]['minute']\n",
    "       \n",
    "        time.append(str(h) + \":\" + str(m))\n",
    "    #substitute the old index with the new one\n",
    "    df['time'] = time\n",
    "    df = df.set_index('time')\n",
    "    df = df.drop(columns=['date'])\n",
    "    return df\n",
    "\n",
    "# per matrix profile invece usa la time series completa\n",
    "\n",
    "ts3 = df.loc[df['day'] == 3] #marted 4 febbraio\n",
    "ts5 = df.loc[df['day'] == 5] #gioved 5 febbraio\n",
    "ts6 = df.loc[df['day'] == 6] # ...\n",
    "ts7 = df.loc[df['day'] == 7] #weekend\n",
    "ts8 = df.loc[df['day'] == 8] #weekend\n",
    "ts9 = df.loc[df['day'] == 9] # primo salto temporale (interruzione delle registrazioni nei giorni 10 e 11)\n",
    "ts12 = df.loc[df['day'] == 12]\n",
    "ts13 = df.loc[df['day'] == 13]\n",
    "ts14 = df.loc[df['day'] == 14] #weekend\n",
    "ts15 = df.loc[df['day'] == 15] #weekend\n",
    "ts16 = df.loc[df['day'] == 16]\n",
    "ts17 = df.loc[df['day'] == 17]\n",
    "\n",
    "\n",
    "ts3 = create_time_index(ts3)\n",
    "ts5 = create_time_index(ts5)\n",
    "ts6 = create_time_index(ts6)\n",
    "ts7 = create_time_index(ts7)\n",
    "ts8 = create_time_index(ts8)\n",
    "ts9 = create_time_index(ts9)\n",
    "ts12 = create_time_index(ts12)\n",
    "ts13 = create_time_index(ts13)\n",
    "ts14 = create_time_index(ts14)\n",
    "ts15 = create_time_index(ts15)\n",
    "ts16 = create_time_index(ts16)\n",
    "ts17 = create_time_index(ts17)\n",
    "\n",
    "variable = 'CO2'\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "ts3 = ts3[variable]\n",
    "ts5 = ts5[variable]\n",
    "ts6 = ts6[variable]\n",
    "ts7 = ts7[variable]\n",
    "ts8 = ts8[variable]\n",
    "ts9 = ts9[variable]\n",
    "ts12 = ts12[variable]\n",
    "ts13 = ts13[variable]\n",
    "ts14 = ts14[variable]\n",
    "ts15 = ts15[variable]\n",
    "ts16 = ts16[variable]\n",
    "ts17 = ts17[variable]\n",
    "\n",
    "\n",
    "sns.set(style = 'whitegrid')\n",
    "plt.ylabel(variable)\n",
    "plt.plot(ts3)\n",
    "plt.plot(ts5)\n",
    "plt.plot(ts6)\n",
    "plt.plot(ts7)\n",
    "plt.plot(ts8)\n",
    "plt.plot(ts9)\n",
    "plt.plot(ts12)\n",
    "plt.plot(ts13)\n",
    "plt.plot(ts14)\n",
    "plt.plot(ts15)\n",
    "plt.plot(ts16)\n",
    "plt.plot(ts17)\n",
    "plt.legend([\"Day 3\", 'Day 5', 'Day 6', 'Day 7', 'Day 8', 'Day 9', 'Day 12', 'Day 13', 'Day 14', 'Day 15', 'Day 16', 'Day 17'])\n",
    "plt.xticks(range(0, 1440, 180))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "L'algoritmo Shapelet discovery richiede un training e un test. Abbiamo diviso il dataset in giorni completi (senza gap),\n",
    "per un totale di 12 giorni, e suddiviso questi giorni in training e test set (9 e 3 ts ciascuno).\n",
    "La variabile da predirre  'weekend', perch ci  sembrato il modo pi ragionevole di associare a ogni time series\n",
    "giornaliera un unico valore numerico da predire.\n",
    "\"\"\"\n",
    "X_train = np.array([ts3, ts5, ts6, ts7, ts8, ts9, ts12, ts13, ts14])\n",
    "X_test = np.array([ts15, ts16, ts17])\n",
    "print(X_train.shape) # 12 ts di lunghezza 1440\n",
    "# weekend = 1 -----> Occupancy = 0\n",
    "#                   3, 5, 6, 7, 8, 9, 12, 13, 14, \n",
    "y_train = np.array([0, 0, 0, 1, 1, 0, 0,  0,  1])\n",
    "#                  15, 16, 17\n",
    "y_test = np.array([1,  0,  0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X = scaler.fit_transform(X).reshape(X.shape[0], X.shape[1])\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 360)\n",
      "(15, 360)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "OPT = ['adam', 'sgd']\n",
    "L = [x/10 for x in range(1, 7)]\n",
    "R = [1, 2]\n",
    "WR = [0.01, 0.1]\n",
    "\n",
    "i = 0\n",
    "summary = []\n",
    "\n",
    "for opt in OPT:\n",
    "    for l in L:\n",
    "        for r in R:\n",
    "            for wr in WR:\n",
    "                print(\"Iteration:\", i+1, \"opt = {}, l = {}, r = {}, wr =  {}\".format(opt, l, r, wr))\n",
    "                n_ts, ts_sz = X_train.shape\n",
    "                n_classes = 2\n",
    "                # Set the number of shapelets per size as done in the original paper\n",
    "                shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                                       ts_sz=ts_sz,\n",
    "                                                                       n_classes=n_classes,\n",
    "                                                                       l=l,\n",
    "                                                                       r=r)\n",
    "\n",
    "                #print('n_ts', n_ts)\n",
    "                #print('ts_sz', ts_sz)\n",
    "                #print('n_classes', n_classes)\n",
    "                #print('shapelet_sizes', shapelet_sizes)\n",
    "\n",
    "                # Define the model using parameters provided by the authors (except that we use\n",
    "                # fewer iterations here)\n",
    "                shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                                        optimizer=opt,\n",
    "                                        weight_regularizer=wr,\n",
    "                                        max_iter=1000,\n",
    "                                        random_state=0)\n",
    "\n",
    "                shp_clf.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = shp_clf.predict(X_test)\n",
    "\n",
    "                predicted_labels = shp_clf.predict(X_test)\n",
    "                #print(\"Correct classification rate:\", accuracy_score(y_test, predicted_labels))\n",
    "                #print(y_test)\n",
    "                #print(predicted_labels)\n",
    "\n",
    "                print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "                print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "                \n",
    "                report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "                summary.append({'iteration' : i,\n",
    "                            'classificator': shp_clf,\n",
    "                            'test_accuracy' : accuracy_score(y_test, y_pred),\n",
    "                            'f1-score [0]' : f1_score(y_test, y_pred, average=None)[0],\n",
    "                            'f1-score [1]' : f1_score(y_test, y_pred, average=None)[1],\n",
    "                            'precision [1]' : report['1']['precision'],\n",
    "                            'recall [1]' : report['1']['recall']})\n",
    "                print(\"---------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%%time\n",
    "OPT = 'sgd'\n",
    "L = [x/10 for x in range(1, 7)]\n",
    "R = [1, 2]\n",
    "WR = [0.01, 0.1]\n",
    "\n",
    "i = 0\n",
    "summary2 = []\n",
    "\n",
    "for l in L:\n",
    "    for r in R:\n",
    "        for wr in WR:\n",
    "            print(\"Iteration:\", i+1, \"opt = {}, l = {}, r = {}, wr =  {}\".format(OPT, l, r, wr))\n",
    "            n_ts, ts_sz = X_train.shape\n",
    "            n_classes = 2\n",
    "            # Set the number of shapelets per size as done in the original paper\n",
    "            shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                                   ts_sz=ts_sz,\n",
    "                                                                   n_classes=n_classes,\n",
    "                                                                   l=l,\n",
    "                                                                   r=r)\n",
    "            #print('n_ts', n_ts)\n",
    "            #print('ts_sz', ts_sz)\n",
    "            #print('n_classes', n_classes)\n",
    "            #print('shapelet_sizes', shapelet_sizes)\n",
    "            # Define the model using parameters provided by the authors (except that we use\n",
    "            # fewer iterations here)\n",
    "            shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                                    optimizer=opt,\n",
    "                                    weight_regularizer=wr,\n",
    "                                    max_iter=1000,\n",
    "                                    random_state=0)\n",
    "            shp_clf.fit(X_train, y_train)\n",
    "            y_pred = shp_clf.predict(X_test)\n",
    "            predicted_labels = shp_clf.predict(X_test)\n",
    "            #print(\"Correct classification rate:\", accuracy_score(y_test, predicted_labels))\n",
    "            #print(y_test)\n",
    "            #print(predicted_labels)\n",
    "            print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "            print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            \n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "            summary2.append({'iteration' : i,\n",
    "                        'classificator': shp_clf,\n",
    "                        'test_accuracy' : accuracy_score(y_test, y_pred),\n",
    "                        'f1-score [0]' : f1_score(y_test, y_pred, average=None)[0],\n",
    "                        'f1-score [1]' : f1_score(y_test, y_pred, average=None)[1],\n",
    "                        'precision [1]' : report['1']['precision'],\n",
    "                        'recall [1]' : report['1']['recall']})\n",
    "            print(\"---------------------------------------------------------\\n\\n\\n\")\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ts 33\n",
      "ts_sz 360\n",
      "n_classes 2\n",
      "shapelet_sizes {108: 3, 216: 3}\n",
      "WARNING:tensorflow:From C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Correct classification rate: 0.9333333333333333\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95652174 0.85714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.88      0.91        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "n_ts, ts_sz = X_train.shape\n",
    "n_classes = 2\n",
    "# Set the number of shapelets per size as done in the original paper\n",
    "shapelet_sizes = grabocka_params_to_shapelet_size_dict(n_ts=n_ts,\n",
    "                                                       ts_sz=ts_sz,\n",
    "                                                       n_classes=n_classes,\n",
    "                                                       l=0.3,\n",
    "                                                       r=2)\n",
    "print('n_ts', n_ts)\n",
    "print('ts_sz', ts_sz)\n",
    "print('n_classes', n_classes)\n",
    "print('shapelet_sizes', shapelet_sizes)\n",
    "# Define the model using parameters provided by the authors (except that we use\n",
    "# fewer iterations here)\n",
    "shp_clf = ShapeletModel(n_shapelets_per_size=shapelet_sizes,\n",
    "                        optimizer='adam',\n",
    "                        weight_regularizer=0.01,\n",
    "                        max_iter=1000,\n",
    "                        random_state=0)\n",
    "shp_clf.fit(X_train, y_train)\n",
    "y_pred = shp_clf.predict(X_test)\n",
    "predicted_labels = shp_clf.predict(X_test)\n",
    "print(\"Correct classification rate:\", accuracy_score(y_test, predicted_labels))\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalla\\Anaconda3\\lib\\site-packages\\tslearn\\utils.py:63: UserWarning: 2-Dimensional data passed. Assuming these are 33 1-dimensional timeseries\n",
      "  '{} 1-dimensional timeseries'.format(X.shape[0]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_locations = shp_clf.locate(X_train)\n",
    "ts_id = 0\n",
    "n_shapelets = sum(shapelet_sizes.values())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    plt.plot(X_test[i], color='slategrey', alpha= 0.4)\n",
    "\n",
    "for idx_shp, shp in enumerate(shp_clf.shapelets_):\n",
    "    t0 = predicted_locations[ts_id, idx_shp]\n",
    "    plt.plot(np.arange(t0, t0 + len(shp)), shp, linewidth=4)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Time [minutes]\", fontsize = 15)\n",
    "plt.ylabel(\"CO2\", fontsize = 15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaplet-distances-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = shp_clf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = shp_clf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(values):\n",
    "    features = {\n",
    "        'avg': np.mean(values),\n",
    "        'std': np.std(values),\n",
    "        'var': np.var(values),\n",
    "        'med': np.median(values),\n",
    "        '10p': np.percentile(values, 10),\n",
    "        '25p': np.percentile(values, 25),\n",
    "        '50p': np.percentile(values, 50),\n",
    "        '75p': np.percentile(values, 75),\n",
    "        '90p': np.percentile(values, 90),\n",
    "        'iqr': np.percentile(values, 75) - np.percentile(values, 25),\n",
    "        'cov': 1.0 * np.mean(values) / np.std(values),\n",
    "        'skw': stats.skew(values),\n",
    "        'kur': stats.kurtosis(values)\n",
    "    }\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = np.array([list(calculate_features(x).values()) for x in X_train])\n",
    "X_test3 = np.array([list(calculate_features(x).values()) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.83333333 0.33333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83        11\n",
      "           1       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.63      0.58      0.58        15\n",
      "weighted avg       0.70      0.73      0.70        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "clf.fit(X_train3, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.90909091 0.75      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.83      0.83        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=6,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=42, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_list = {'min_samples_split': [_ for _ in range(1, 10, 5)],\n",
    "              'min_samples_leaf': [_ for _ in range(1, 10, 5)],\n",
    "              'max_depth': [_ for _ in range(1, 5)]\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_list, cv=5)\n",
    "grid_search.fit(X_train3, y_train)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='dtw_sakoechiba',\n",
       "                     metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyts.classification import KNeighborsClassifier\n",
    "parameters = {'n_neighbors': np.arange(1, 10 + 1), \n",
    "              'weights': ['uniform', 'distance'],\n",
    "             'metric' : ['dtw_sakoechiba']}\n",
    " \n",
    "knn = KNeighborsClassifier()\n",
    "search = GridSearchCV(knn, parameters)\n",
    "search.fit(X_train3, y_train)\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.8 0.6]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.69      0.74      0.70        15\n",
      "weighted avg       0.79      0.73      0.75        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='dtw_sakoechiba',\n",
      "                     metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "clf = search.best_estimator_\n",
    "\n",
    "clf.fit(X_train3, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.classification import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.9 0.8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.91      0.85        15\n",
      "weighted avg       0.91      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 0 0 1 0 0 0 0 1 0]\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='dtw_sakoechiba',\n",
      "                     metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(metric='dtw_sakoechiba', weights = 'distance', n_neighbors = 2)\n",
    "clf.fit(X_train3, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test3)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, Activation, Conv1D, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 10s 396ms/step - loss: 0.7016 - acc: 0.5769 - val_loss: 0.7708 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6923 - acc: 0.6923 - val_loss: 0.6729 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6755 - acc: 0.7308 - val_loss: 0.6676 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6735 - acc: 0.7308 - val_loss: 0.6793 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.6633 - acc: 0.7308 - val_loss: 0.6788 - val_acc: 0.8571\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95238095 0.88888889]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.90      0.95      0.92        15\n",
      "weighted avg       0.95      0.93      0.94        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6754416823387146, 0.9333333373069763]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "cnn = build_simple_cnn(n_timesteps, n_outputs)\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history\n",
    "\n",
    "y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 0 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_26 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 17s 638ms/step - loss: 0.6935 - acc: 0.5385 - val_loss: 2.3143 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6888 - acc: 0.7308 - val_loss: 1.1739 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6908 - acc: 0.7308 - val_loss: 1.5296 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6562 - acc: 0.6923 - val_loss: 1.1216 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6527 - acc: 0.7308 - val_loss: 0.7220 - val_acc: 0.4286\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.16666667 0.44444444]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        11\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.64      0.55      0.31        15\n",
      "weighted avg       0.81      0.33      0.24        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 1 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 16s 616ms/step - loss: 0.7085 - acc: 0.5385 - val_loss: 1.1553 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6830 - acc: 0.7308 - val_loss: 0.5971 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6838 - acc: 0.7308 - val_loss: 0.6660 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6582 - acc: 0.7308 - val_loss: 0.7056 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6322 - acc: 0.7308 - val_loss: 0.7307 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 2 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_14  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 16s 626ms/step - loss: 0.7356 - acc: 0.5000 - val_loss: 0.6958 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7099 - acc: 0.5769 - val_loss: 0.6834 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6933 - acc: 0.6154 - val_loss: 0.6776 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6808 - acc: 0.6923 - val_loss: 0.6950 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6814 - acc: 0.5000 - val_loss: 0.6991 - val_acc: 0.4286\n",
      "Accuracy 0.13333333333333333\n",
      "F1-score [0.13333333 0.13333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        11\n",
      "           1       0.09      0.25      0.13         4\n",
      "\n",
      "    accuracy                           0.13        15\n",
      "   macro avg       0.17      0.17      0.13        15\n",
      "weighted avg       0.21      0.13      0.13        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 1 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 3 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_32 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_15  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 18s 689ms/step - loss: 0.7380 - acc: 0.6154 - val_loss: 0.6438 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7030 - acc: 0.6538 - val_loss: 0.6314 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6904 - acc: 0.5769 - val_loss: 0.6253 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6694 - acc: 0.7308 - val_loss: 0.6550 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6556 - acc: 0.7308 - val_loss: 0.7199 - val_acc: 0.4286\n",
      "Accuracy 0.06666666666666667\n",
      "F1-score [0.125 0.   ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.09      0.13        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07        15\n",
      "   macro avg       0.10      0.05      0.06        15\n",
      "weighted avg       0.15      0.07      0.09        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 4 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_34 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 18s 688ms/step - loss: 0.7073 - acc: 0.4615 - val_loss: 0.7505 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6796 - acc: 0.6923 - val_loss: 0.6721 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6566 - acc: 0.7692 - val_loss: 0.6756 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6436 - acc: 0.7308 - val_loss: 0.6791 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6086 - acc: 0.7308 - val_loss: 0.6968 - val_acc: 0.5714\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.9 0.8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.91      0.85        15\n",
      "weighted avg       0.91      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 0 0 0 1 0 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "============================================ 5 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 18s 694ms/step - loss: 0.6858 - acc: 0.6538 - val_loss: 0.6548 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6808 - acc: 0.7308 - val_loss: 0.6407 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6594 - acc: 0.7308 - val_loss: 0.6600 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6389 - acc: 0.7308 - val_loss: 0.7376 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6348 - acc: 0.7308 - val_loss: 0.7346 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 6 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_38 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_18  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 19s 736ms/step - loss: 0.6911 - acc: 0.7308 - val_loss: 0.7212 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6725 - acc: 0.7308 - val_loss: 0.7362 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6394 - acc: 0.7308 - val_loss: 0.7664 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6296 - acc: 0.7308 - val_loss: 0.7292 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5961 - acc: 0.7308 - val_loss: 0.6440 - val_acc: 0.8571\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 7 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_40 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_19  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 20s 752ms/step - loss: 0.7069 - acc: 0.5385 - val_loss: 0.6930 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6844 - acc: 0.6154 - val_loss: 0.6741 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6687 - acc: 0.7308 - val_loss: 0.5805 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6513 - acc: 0.7308 - val_loss: 0.5829 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6409 - acc: 0.7308 - val_loss: 0.5719 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 8 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 20s 773ms/step - loss: 0.6205 - acc: 0.7308 - val_loss: 4.3206 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7062 - acc: 0.7308 - val_loss: 2.8367 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7290 - acc: 0.7308 - val_loss: 0.8075 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6665 - acc: 0.7308 - val_loss: 0.6928 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6529 - acc: 0.7308 - val_loss: 0.9082 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 1ms/step\n",
      "============================================ 9 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 22s 838ms/step - loss: 0.7162 - acc: 0.6538 - val_loss: 1.0145 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6695 - acc: 0.7308 - val_loss: 0.9041 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6641 - acc: 0.7692 - val_loss: 1.3293 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6427 - acc: 0.7308 - val_loss: 1.1410 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6309 - acc: 0.6538 - val_loss: 0.7208 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 10 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_22  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 22s 829ms/step - loss: 0.6901 - acc: 0.6538 - val_loss: 0.7044 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6889 - acc: 0.681 - 0s 17ms/step - loss: 0.6769 - acc: 0.7308 - val_loss: 0.6724 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6649 - acc: 0.7308 - val_loss: 0.6737 - val_acc: 0.8571\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6496 - acc: 0.7308 - val_loss: 0.7767 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6259 - acc: 0.7308 - val_loss: 0.7459 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 11 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d_49 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 22s 848ms/step - loss: 0.6932 - acc: 0.6923 - val_loss: 0.9227 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6897 - acc: 0.6154 - val_loss: 0.7928 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6693 - acc: 0.6538 - val_loss: 0.6491 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6403 - acc: 0.7308 - val_loss: 0.7410 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6243 - acc: 0.7308 - val_loss: 0.7284 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 12 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_50 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_24  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 23s 903ms/step - loss: 0.6706 - acc: 0.7308 - val_loss: 0.9681 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6626 - acc: 0.7308 - val_loss: 0.7915 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6325 - acc: 0.7308 - val_loss: 0.7941 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6288 - acc: 0.7308 - val_loss: 0.8262 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6211 - acc: 0.7308 - val_loss: 0.7674 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 13 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 23s 887ms/step - loss: 0.7405 - acc: 0.5769 - val_loss: 0.7126 - val_acc: 0.1429\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6949 - acc: 0.5385 - val_loss: 1.1844 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6779 - acc: 0.7308 - val_loss: 0.9928 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6702 - acc: 0.7308 - val_loss: 1.2067 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6540 - acc: 0.6923 - val_loss: 1.1224 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "activation_55 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.7293 - acc: 0.6923 - val_loss: 0.7451 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6765 - acc: 0.7308 - val_loss: 0.6436 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6483 - acc: 0.7308 - val_loss: 0.6398 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6382 - acc: 0.7308 - val_loss: 0.9542 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6018 - acc: 0.7308 - val_loss: 0.8108 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 15 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_27  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 25s 979ms/step - loss: 0.6990 - acc: 0.4615 - val_loss: 0.5957 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6879 - acc: 0.6154 - val_loss: 0.6110 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6856 - acc: 0.6923 - val_loss: 0.6643 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6921 - acc: 0.7308 - val_loss: 0.7314 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.6503 - acc: 0.7692 - val_loss: 1.0101 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 16 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_58 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_28  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 25s 968ms/step - loss: 0.6740 - acc: 0.7308 - val_loss: 1.1811 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6494 - acc: 0.7308 - val_loss: 1.2604 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6565 - acc: 0.7308 - val_loss: 1.1280 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6277 - acc: 0.7308 - val_loss: 1.1290 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6009 - acc: 0.7308 - val_loss: 1.0772 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 17 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_61 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_29  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 26s 997ms/step - loss: 0.8062 - acc: 0.6154 - val_loss: 2.7709 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.7314 - acc: 0.5769 - val_loss: 1.0039 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6453 - acc: 0.7308 - val_loss: 1.1288 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6285 - acc: 0.7308 - val_loss: 1.0037 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6151 - acc: 0.7308 - val_loss: 1.2186 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 18 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_62 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_30  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.7026 - acc: 0.5769 - val_loss: 0.5827 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6752 - acc: 0.7308 - val_loss: 0.6330 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6548 - acc: 0.7308 - val_loss: 0.6281 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6118 - acc: 0.7308 - val_loss: 0.6515 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5982 - acc: 0.7308 - val_loss: 0.6542 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 19 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_31  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.8316 - acc: 0.5385 - val_loss: 0.6728 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7285 - acc: 0.4615 - val_loss: 0.6087 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6986 - acc: 0.5769 - val_loss: 0.6320 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6780 - acc: 0.7308 - val_loss: 0.6111 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6711 - acc: 0.7308 - val_loss: 0.6162 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 20 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_32  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.7594 - acc: 0.4615 - val_loss: 0.7855 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6804 - acc: 0.6154 - val_loss: 1.0593 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6643 - acc: 0.7308 - val_loss: 1.3786 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6380 - acc: 0.7308 - val_loss: 1.2665 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6554 - acc: 0.7308 - val_loss: 1.0336 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 21 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_68 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_33  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 29s 1s/step - loss: 0.7159 - acc: 0.5000 - val_loss: 1.0117 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6686 - acc: 0.7308 - val_loss: 2.4345 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6517 - acc: 0.7308 - val_loss: 1.7807 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6435 - acc: 0.7308 - val_loss: 1.8559 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6360 - acc: 0.7308 - val_loss: 1.9081 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 22 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_34  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 30s 1s/step - loss: 0.7043 - acc: 0.6923 - val_loss: 0.6929 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6959 - acc: 0.5769 - val_loss: 0.6904 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6901 - acc: 0.6538 - val_loss: 0.6834 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6768 - acc: 0.6923 - val_loss: 0.6771 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6645 - acc: 0.7308 - val_loss: 0.6758 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 23 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_average_pooling1d_35  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 32s 1s/step - loss: 0.7078 - acc: 0.5385 - val_loss: 3.0424 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6853 - acc: 0.6538 - val_loss: 2.5445 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7055 - acc: 0.6538 - val_loss: 1.7003 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7079 - acc: 0.6538 - val_loss: 1.0682 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6937 - acc: 0.7308 - val_loss: 0.6521 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 24 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_74 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_36  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 34s 1s/step - loss: 0.6989 - acc: 0.6538 - val_loss: 0.6096 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6945 - acc: 0.7692 - val_loss: 0.6696 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6582 - acc: 0.6923 - val_loss: 0.6748 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6717 - acc: 0.7308 - val_loss: 0.6567 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6910 - acc: 0.6538 - val_loss: 0.6602 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 25 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_76 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_37  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.6823 - acc: 0.7308 - val_loss: 2.1373 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6646 - acc: 0.7308 - val_loss: 0.7043 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6612 - acc: 0.7308 - val_loss: 0.7501 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6311 - acc: 0.7308 - val_loss: 0.7580 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.5900 - acc: 0.7308 - val_loss: 1.1787 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 26 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_38  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.7785 - acc: 0.4231 - val_loss: 1.5026 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7261 - acc: 0.5769 - val_loss: 0.6563 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6879 - acc: 0.6538 - val_loss: 0.7822 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6862 - acc: 0.6923 - val_loss: 0.6760 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6721 - acc: 0.6923 - val_loss: 0.7073 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 27 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_80 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_39  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 33s 1s/step - loss: 0.7261 - acc: 0.5000 - val_loss: 1.0104 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.7124 - acc: 0.6538 - val_loss: 0.6012 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6738 - acc: 0.6923 - val_loss: 0.6827 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6276 - acc: 0.6923 - val_loss: 0.7114 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5971 - acc: 0.6538 - val_loss: 0.7063 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 28 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_82 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_40  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 35s 1s/step - loss: 0.6762 - acc: 0.6923 - val_loss: 0.9412 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6320 - acc: 0.7308 - val_loss: 0.7204 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6383 - acc: 0.7308 - val_loss: 0.6818 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6349 - acc: 0.7308 - val_loss: 0.6935 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.5982 - acc: 0.7308 - val_loss: 1.6845 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 29 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_41  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.7043 - acc: 0.6538 - val_loss: 0.9948 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6421 - acc: 0.6538 - val_loss: 0.6860 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6485 - acc: 0.6923 - val_loss: 0.6773 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6131 - acc: 0.6923 - val_loss: 0.6706 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.5618 - acc: 0.6538 - val_loss: 0.6617 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 30 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_86 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_42  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 36s 1s/step - loss: 0.7159 - acc: 0.5769 - val_loss: 2.2700 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6837 - acc: 0.6923 - val_loss: 0.7824 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6773 - acc: 0.6923 - val_loss: 0.6712 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6446 - acc: 0.7308 - val_loss: 0.6973 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.6378 - acc: 0.7308 - val_loss: 0.7008 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 31 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_43  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 37s 1s/step - loss: 0.7151 - acc: 0.6154 - val_loss: 0.9257 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6932 - acc: 0.6538 - val_loss: 0.7344 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6889 - acc: 0.6923 - val_loss: 0.6922 - val_acc: 0.5714\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6633 - acc: 0.7308 - val_loss: 0.6618 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6572 - acc: 0.7308 - val_loss: 0.6377 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 32 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_44  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 38s 1s/step - loss: 0.7501 - acc: 0.6154 - val_loss: 0.7543 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.7629 - acc: 0.3846 - val_loss: 0.6481 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6796 - acc: 0.6923 - val_loss: 0.6113 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6784 - acc: 0.6923 - val_loss: 0.6169 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 0.6156 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 33 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_45  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 39s 1s/step - loss: 0.7632 - acc: 0.5000 - val_loss: 0.6990 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6872 - acc: 0.6923 - val_loss: 0.9328 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6604 - acc: 0.6154 - val_loss: 1.2114 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6670 - acc: 0.7308 - val_loss: 1.5279 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6263 - acc: 0.7308 - val_loss: 1.4169 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 34 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_46  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 40s 2s/step - loss: 0.7043 - acc: 0.5769 - val_loss: 0.5958 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6853 - acc: 0.7692 - val_loss: 0.6107 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6804 - acc: 0.7308 - val_loss: 0.6128 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6546 - acc: 0.6538 - val_loss: 0.6801 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6271 - acc: 0.7308 - val_loss: 0.6286 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 35 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_47  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 43s 2s/step - loss: 0.7298 - acc: 0.5769 - val_loss: 0.6928 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6945 - acc: 0.5385 - val_loss: 0.6917 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6736 - acc: 0.6538 - val_loss: 0.6924 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6601 - acc: 0.5385 - val_loss: 0.6828 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6172 - acc: 0.6923 - val_loss: 0.6440 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 36 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_48  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 43s 2s/step - loss: 0.7061 - acc: 0.7308 - val_loss: 0.7181 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6816 - acc: 0.7308 - val_loss: 3.1154 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6446 - acc: 0.6923 - val_loss: 3.3250 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 0.6061 - acc: 0.7692 - val_loss: 3.5793 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.5906 - acc: 0.6923 - val_loss: 3.1044 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 37 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_127 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_128 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_49  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 43s 2s/step - loss: 0.6691 - acc: 0.6154 - val_loss: 0.6394 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 0.6405 - acc: 0.7308 - val_loss: 0.6256 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6596 - acc: 0.7308 - val_loss: 0.6338 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6338 - acc: 0.7308 - val_loss: 0.6350 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6006 - acc: 0.7308 - val_loss: 0.6356 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 38 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_129 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_130 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_50  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.6982 - acc: 0.5000 - val_loss: 0.6093 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6680 - acc: 0.7308 - val_loss: 0.9343 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.7057 - acc: 0.6538 - val_loss: 0.6254 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.7043 - acc: 0.7308 - val_loss: 0.7129 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6412 - acc: 0.6154 - val_loss: 0.7172 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 39 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_51  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.7989 - acc: 0.5000 - val_loss: 0.7075 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6996 - acc: 0.5000 - val_loss: 0.6847 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6674 - acc: 0.7308 - val_loss: 0.6838 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6449 - acc: 0.7308 - val_loss: 0.6772 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 25ms/step - loss: 0.6143 - acc: 0.7308 - val_loss: 0.6785 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 40 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_134 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_52  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 46s 2s/step - loss: 0.7736 - acc: 0.5385 - val_loss: 0.7203 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.7071 - acc: 0.5769 - val_loss: 0.6547 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6782 - acc: 0.7308 - val_loss: 0.6290 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.6748 - acc: 0.7308 - val_loss: 0.6193 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6746 - acc: 0.6923 - val_loss: 0.6473 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 41 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_135 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_136 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_53  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.6956 - acc: 0.6923 - val_loss: 0.6654 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6399 - acc: 0.7308 - val_loss: 1.1430 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6741 - acc: 0.7308 - val_loss: 0.7626 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6448 - acc: 0.7308 - val_loss: 0.6716 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6529 - acc: 0.7308 - val_loss: 0.6612 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.90909091 0.75      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.83      0.83        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 42 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_137 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_138 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_54  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.7581 - acc: 0.4231 - val_loss: 0.7017 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6968 - acc: 0.5000 - val_loss: 0.6587 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6720 - acc: 0.6923 - val_loss: 0.6189 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6593 - acc: 0.7308 - val_loss: 0.5781 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6607 - acc: 0.6923 - val_loss: 0.5790 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 43 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_112 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_140 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_55  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.7749 - acc: 0.4231 - val_loss: 0.6393 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.6967 - acc: 0.6154 - val_loss: 1.5806 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6583 - acc: 0.7308 - val_loss: 1.5798 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6910 - acc: 0.6923 - val_loss: 0.9503 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.7022 - acc: 0.6923 - val_loss: 0.7500 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 44 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_141 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_142 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_56  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.7131 - acc: 0.2692 - val_loss: 1.3470 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 0.6804 - acc: 0.6923 - val_loss: 0.8461 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7141 - acc: 0.7308 - val_loss: 0.6546 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 27ms/step - loss: 0.6727 - acc: 0.7308 - val_loss: 0.6684 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6759 - acc: 0.7308 - val_loss: 0.6862 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 45 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_143 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1d_117 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_144 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_57  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 51s 2s/step - loss: 0.7212 - acc: 0.7308 - val_loss: 0.6146 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6651 - acc: 0.7308 - val_loss: 0.6836 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6543 - acc: 0.7308 - val_loss: 0.6861 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6062 - acc: 0.7308 - val_loss: 0.6813 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.5888 - acc: 0.7308 - val_loss: 0.6614 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 46 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_118 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_145 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_146 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_58  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 52s 2s/step - loss: 0.7942 - acc: 0.6154 - val_loss: 1.1528 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.7138 - acc: 0.6923 - val_loss: 0.6440 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6967 - acc: 0.7308 - val_loss: 0.6452 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6817 - acc: 0.6154 - val_loss: 0.6585 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 26ms/step - loss: 0.6800 - acc: 0.6538 - val_loss: 0.6542 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 47 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_148 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_59  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 53s 2s/step - loss: 0.6958 - acc: 0.4615 - val_loss: 2.5609 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6670 - acc: 0.7308 - val_loss: 1.0588 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6686 - acc: 0.7308 - val_loss: 0.7025 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.6506 - acc: 0.7308 - val_loss: 1.0234 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6328 - acc: 0.7308 - val_loss: 0.8913 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_122 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_149 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_150 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_60  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 54s 2s/step - loss: 0.7001 - acc: 0.5000 - val_loss: 1.6765 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6907 - acc: 0.5385 - val_loss: 1.3256 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6654 - acc: 0.6538 - val_loss: 1.3287 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6676 - acc: 0.6538 - val_loss: 1.5252 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.6432 - acc: 0.7308 - val_loss: 1.2150 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 49 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_151 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_152 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_61  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 57s 2s/step - loss: 0.7005 - acc: 0.6538 - val_loss: 0.6452 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.6499 - acc: 0.7308 - val_loss: 0.6923 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6099 - acc: 0.6923 - val_loss: 0.6612 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6056 - acc: 0.7308 - val_loss: 0.6639 - val_acc: 0.8571\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.5300 - acc: 0.8462 - val_loss: 0.6708 - val_acc: 0.8571\n",
      "Accuracy 0.4666666666666667\n",
      "F1-score [0.42857143 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43        11\n",
      "           1       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.67      0.64      0.46        15\n",
      "weighted avg       0.82      0.47      0.45        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 1 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 50 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_153 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_154 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_62  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 56s 2s/step - loss: 0.7345 - acc: 0.6923 - val_loss: 0.9734 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7155 - acc: 0.5769 - val_loss: 0.7500 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6826 - acc: 0.5385 - val_loss: 0.6636 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6434 - acc: 0.7308 - val_loss: 0.6571 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 0.5947 - acc: 0.7308 - val_loss: 0.6667 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.91666667 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.92      0.75      0.79        15\n",
      "weighted avg       0.89      0.87      0.85        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 51 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_128 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_156 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_63  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 57s 2s/step - loss: 0.6860 - acc: 0.6923 - val_loss: 0.6814 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.6821 - acc: 0.7308 - val_loss: 0.6852 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6653 - acc: 0.7308 - val_loss: 0.6756 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6689 - acc: 0.7308 - val_loss: 0.6683 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6530 - acc: 0.7308 - val_loss: 0.7247 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 52 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_157 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_158 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_64  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 58s 2s/step - loss: 0.6980 - acc: 0.6923 - val_loss: 2.0375 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6908 - acc: 0.6538 - val_loss: 0.7809 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 30ms/step - loss: 0.6592 - acc: 0.7692 - val_loss: 0.8775 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6453 - acc: 0.7308 - val_loss: 0.6874 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.5916 - acc: 0.6538 - val_loss: 0.6257 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "============================================ 53 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_159 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_160 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_65  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 59s 2s/step - loss: 0.7111 - acc: 0.5000 - val_loss: 1.1351 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 0.6903 - acc: 0.6923 - val_loss: 1.1951 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6926 - acc: 0.7308 - val_loss: 0.8721 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6574 - acc: 0.6923 - val_loss: 0.8362 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6651 - acc: 0.7308 - val_loss: 0.8073 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 54 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_134 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_161 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_195 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_162 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_66  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 61s 2s/step - loss: 0.7242 - acc: 0.5769 - val_loss: 1.8327 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7078 - acc: 0.6154 - val_loss: 0.9098 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6920 - acc: 0.7308 - val_loss: 0.8043 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6892 - acc: 0.6154 - val_loss: 0.6540 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.6581 - acc: 0.8077 - val_loss: 0.6721 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 55 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_136 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_164 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_198 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_67  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 62s 2s/step - loss: 0.6538 - acc: 0.7308 - val_loss: 3.8042 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6994 - acc: 0.7308 - val_loss: 0.7876 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6618 - acc: 0.7308 - val_loss: 1.5550 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.6721 - acc: 0.7308 - val_loss: 2.0086 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6235 - acc: 0.7692 - val_loss: 2.0209 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 56 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_138 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_165 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_199 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_166 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_200 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_68  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 64s 2s/step - loss: 0.6923 - acc: 0.6154 - val_loss: 1.1375 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6695 - acc: 0.7308 - val_loss: 0.6989 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6524 - acc: 0.7308 - val_loss: 0.6760 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6399 - acc: 0.7308 - val_loss: 0.6716 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.5963 - acc: 0.7308 - val_loss: 0.7243 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 57 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_167 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_201 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_168 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_202 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_69  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 68s 3s/step - loss: 0.6929 - acc: 0.6154 - val_loss: 1.3046 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 0.7129 - acc: 0.7308 - val_loss: 1.4088 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6617 - acc: 0.7308 - val_loss: 1.8485 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6614 - acc: 0.5769 - val_loss: 1.1971 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6208 - acc: 0.6923 - val_loss: 0.7686 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 58 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_142 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_169 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_170 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_70  (None, 64)                0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_123 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 66s 3s/step - loss: 0.6990 - acc: 0.3077 - val_loss: 1.2568 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6890 - acc: 0.6154 - val_loss: 1.4545 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7093 - acc: 0.7308 - val_loss: 0.6850 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6701 - acc: 0.7308 - val_loss: 0.7593 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6912 - acc: 0.7308 - val_loss: 0.8041 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 59 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_144 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_205 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_172 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_206 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_71  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 85s 3s/step - loss: 0.7191 - acc: 0.5000 - val_loss: 1.2693 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6944 - acc: 0.6538 - val_loss: 0.7006 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6726 - acc: 0.7308 - val_loss: 0.6825 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.6665 - acc: 0.7308 - val_loss: 0.6747 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6386 - acc: 0.7308 - val_loss: 0.6585 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 60 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_173 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_207 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_208 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_72  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 83s 3s/step - loss: 0.7257 - acc: 0.3462 - val_loss: 0.7590 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6791 - acc: 0.7308 - val_loss: 0.6973 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.6793 - acc: 0.7308 - val_loss: 0.6495 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6542 - acc: 0.7308 - val_loss: 0.6295 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6259 - acc: 0.7308 - val_loss: 0.6256 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 61 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_148 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_209 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_210 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_73  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 82s 3s/step - loss: 0.6900 - acc: 0.6923 - val_loss: 0.6886 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6244 - acc: 0.7308 - val_loss: 0.6406 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6517 - acc: 0.7308 - val_loss: 0.6649 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.6790 - acc: 0.7308 - val_loss: 0.6667 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6364 - acc: 0.7308 - val_loss: 0.6733 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 62 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_150 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_177 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_212 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_74  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 84s 3s/step - loss: 0.7004 - acc: 0.6538 - val_loss: 1.2501 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.6801 - acc: 0.7308 - val_loss: 0.6232 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6802 - acc: 0.7308 - val_loss: 0.6488 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.6459 - acc: 0.7308 - val_loss: 0.6457 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6365 - acc: 0.7308 - val_loss: 0.6457 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 63 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_152 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_213 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_180 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_214 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_75  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 89s 3s/step - loss: 0.7718 - acc: 0.4231 - val_loss: 1.3358 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6787 - acc: 0.7692 - val_loss: 1.7592 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7023 - acc: 0.5769 - val_loss: 1.8280 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6750 - acc: 0.6923 - val_loss: 1.5164 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6573 - acc: 0.7308 - val_loss: 1.1830 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 64 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_215 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_182 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_76  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 88s 3s/step - loss: 0.6819 - acc: 0.7308 - val_loss: 1.6508 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6553 - acc: 0.7308 - val_loss: 0.6361 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6308 - acc: 0.7308 - val_loss: 1.1594 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6557 - acc: 0.7308 - val_loss: 1.6107 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6143 - acc: 0.7308 - val_loss: 0.7382 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 65 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_183 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_77  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 85s 3s/step - loss: 0.7056 - acc: 0.6923 - val_loss: 0.9961 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6759 - acc: 0.6923 - val_loss: 0.8835 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6552 - acc: 0.7692 - val_loss: 0.7740 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6512 - acc: 0.7308 - val_loss: 0.6685 - val_acc: 0.5714\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6297 - acc: 0.7308 - val_loss: 0.6461 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 3ms/step\n",
      "============================================ 66 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_158 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "batch_normalization_186 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_78  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 86s 3s/step - loss: 0.6899 - acc: 0.6538 - val_loss: 2.0375 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6874 - acc: 0.5769 - val_loss: 0.7895 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6573 - acc: 0.7308 - val_loss: 0.8832 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6335 - acc: 0.6538 - val_loss: 0.8759 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6000 - acc: 0.7308 - val_loss: 0.8431 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 67 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_160 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_79  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 89s 3s/step - loss: 0.6959 - acc: 0.5385 - val_loss: 0.6837 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6833 - acc: 0.6538 - val_loss: 0.6868 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6748 - acc: 0.7308 - val_loss: 0.6685 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6559 - acc: 0.7308 - val_loss: 0.6583 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6373 - acc: 0.7308 - val_loss: 0.6927 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 68 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_189 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_80  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 94s 4s/step - loss: 0.7097 - acc: 0.6538 - val_loss: 0.6650 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.6722 - acc: 0.7308 - val_loss: 0.6455 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7060 - acc: 0.7308 - val_loss: 0.6290 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6799 - acc: 0.7308 - val_loss: 0.6436 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.6529 - acc: 0.7308 - val_loss: 0.6499 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 69 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_164 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_81  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 90s 3s/step - loss: 0.6999 - acc: 0.7308 - val_loss: 3.9962 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6247 - acc: 0.7692 - val_loss: 1.5803 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6568 - acc: 0.6154 - val_loss: 0.6490 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.5501 - acc: 0.7308 - val_loss: 0.6292 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.5577 - acc: 0.6538 - val_loss: 0.6416 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 70 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_82  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.7213 - acc: 0.6154 - val_loss: 0.7174 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6889 - acc: 0.6538 - val_loss: 0.7083 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.6426 - acc: 0.7692 - val_loss: 0.7009 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6298 - acc: 0.6538 - val_loss: 0.6925 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6096 - acc: 0.6154 - val_loss: 0.6710 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 71 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_168 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_230 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_83  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 99s 4s/step - loss: 0.7077 - acc: 0.7308 - val_loss: 0.8922 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6476 - acc: 0.7308 - val_loss: 0.7126 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6230 - acc: 0.6538 - val_loss: 0.8528 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6082 - acc: 0.6923 - val_loss: 0.6879 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.5262 - acc: 0.7308 - val_loss: 0.6877 - val_acc: 0.2857\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.16666667 0.44444444]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        11\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.64      0.55      0.31        15\n",
      "weighted avg       0.81      0.33      0.24        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 72 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_170 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_84  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 103s 4s/step - loss: 0.7002 - acc: 0.5385 - val_loss: 4.5990 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6926 - acc: 0.7308 - val_loss: 1.5505 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6839 - acc: 0.7308 - val_loss: 1.0366 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.6577 - acc: 0.7308 - val_loss: 0.8649 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6315 - acc: 0.6538 - val_loss: 1.0620 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 73 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_172 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_233 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_234 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_85  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 100s 4s/step - loss: 0.6996 - acc: 0.5769 - val_loss: 1.2197 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6887 - acc: 0.7308 - val_loss: 0.9168 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6906 - acc: 0.6923 - val_loss: 1.1485 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6808 - acc: 0.7308 - val_loss: 0.7716 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6601 - acc: 0.7308 - val_loss: 0.6628 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 74 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_174 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_235 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_236 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_86  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 102s 4s/step - loss: 0.7483 - acc: 0.4615 - val_loss: 0.6258 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.7099 - acc: 0.5769 - val_loss: 0.6345 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.6802 - acc: 0.6538 - val_loss: 0.9040 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6770 - acc: 0.6154 - val_loss: 0.8180 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6740 - acc: 0.7308 - val_loss: 0.8567 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 75 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_176 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_237 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_87  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 97s 4s/step - loss: 0.7051 - acc: 0.6538 - val_loss: 0.6897 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6906 - acc: 0.6538 - val_loss: 0.6776 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6700 - acc: 0.6538 - val_loss: 0.6789 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 0.6399 - acc: 0.7308 - val_loss: 0.7007 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6007 - acc: 0.7308 - val_loss: 0.7106 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 76 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_178 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_240 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_88  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 96s 4s/step - loss: 0.6710 - acc: 0.7308 - val_loss: 1.2252 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6681 - acc: 0.6154 - val_loss: 0.8251 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 0.7036 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6271 - acc: 0.7308 - val_loss: 0.6854 - val_acc: 0.5714\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6223 - acc: 0.7308 - val_loss: 0.6693 - val_acc: 0.7143\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95238095 0.88888889]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.90      0.95      0.92        15\n",
      "weighted avg       0.95      0.93      0.94        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 77 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_180 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_241 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_89  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 100s 4s/step - loss: 0.7026 - acc: 0.6923 - val_loss: 2.8969 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7174 - acc: 0.6538 - val_loss: 0.7720 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6557 - acc: 0.6923 - val_loss: 0.7036 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6447 - acc: 0.6154 - val_loss: 0.6917 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.5862 - acc: 0.7692 - val_loss: 0.6855 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 78 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_182 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_244 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_90  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 95s 4s/step - loss: 0.7383 - acc: 0.6154 - val_loss: 1.8053 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6888 - acc: 0.6923 - val_loss: 1.0354 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6698 - acc: 0.6923 - val_loss: 0.7495 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.5963 - acc: 0.7692 - val_loss: 0.8252 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.5473 - acc: 0.6923 - val_loss: 0.7639 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 79 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_184 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_91  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 98s 4s/step - loss: 0.7153 - acc: 0.6538 - val_loss: 0.7166 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6902 - acc: 0.5385 - val_loss: 0.7832 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6567 - acc: 0.5769 - val_loss: 0.7183 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.6417 - acc: 0.6923 - val_loss: 0.8361 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6319 - acc: 0.7308 - val_loss: 1.0309 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 4ms/step\n",
      "============================================ 80 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_186 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_247 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_248 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_92  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 100s 4s/step - loss: 0.7254 - acc: 0.6538 - val_loss: 1.1232 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 0.6821 - acc: 0.7308 - val_loss: 0.8753 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.6734 - acc: 0.6538 - val_loss: 0.8236 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6693 - acc: 0.6923 - val_loss: 0.7918 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6390 - acc: 0.7308 - val_loss: 0.7536 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 81 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_188 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_249 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_189 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_250 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_93  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 103s 4s/step - loss: 0.6999 - acc: 0.5769 - val_loss: 0.7698 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6564 - acc: 0.7308 - val_loss: 0.6226 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6589 - acc: 0.7308 - val_loss: 0.7204 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6848 - acc: 0.7308 - val_loss: 0.6467 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6442 - acc: 0.7308 - val_loss: 0.6821 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 82 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_190 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_251 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_191 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_252 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_94  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 99s 4s/step - loss: 0.6859 - acc: 0.6923 - val_loss: 0.7276 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6732 - acc: 0.7308 - val_loss: 0.6599 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6868 - acc: 0.7308 - val_loss: 0.6828 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6543 - acc: 0.7308 - val_loss: 0.6820 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6484 - acc: 0.7308 - val_loss: 0.6977 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 83 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_192 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_253 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_193 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_254 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_95  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 100s 4s/step - loss: 0.7240 - acc: 0.3462 - val_loss: 0.9154 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6906 - acc: 0.6154 - val_loss: 0.8635 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7047 - acc: 0.7308 - val_loss: 0.6931 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6793 - acc: 0.7308 - val_loss: 0.6865 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.6681 - acc: 0.7308 - val_loss: 0.7141 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 84 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_194 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_255 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_195 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_256 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_96  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 104s 4s/step - loss: 0.6866 - acc: 0.6538 - val_loss: 0.6809 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6837 - acc: 0.7308 - val_loss: 0.7227 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6427 - acc: 0.7308 - val_loss: 0.6900 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.6613 - acc: 0.7308 - val_loss: 0.7072 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6478 - acc: 0.7308 - val_loss: 0.7012 - val_acc: 0.7143\n",
      "Accuracy 0.6\n",
      "F1-score [0.75 0.  ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.35      0.41      0.38        15\n",
      "weighted avg       0.51      0.60      0.55        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 85 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_196 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_257 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_197 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_258 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_97  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 110s 4s/step - loss: 0.7051 - acc: 0.6923 - val_loss: 0.7085 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6743 - acc: 0.6538 - val_loss: 0.6294 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6466 - acc: 0.6538 - val_loss: 0.6125 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.6104 - acc: 0.6923 - val_loss: 0.6028 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.5616 - acc: 0.7308 - val_loss: 0.6037 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 86 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_198 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_259 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_199 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_260 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_98  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 111s 4s/step - loss: 0.7131 - acc: 0.5769 - val_loss: 0.6766 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6708 - acc: 0.7308 - val_loss: 0.8527 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6237 - acc: 0.7308 - val_loss: 1.0864 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6326 - acc: 0.6154 - val_loss: 1.0225 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.5966 - acc: 0.6538 - val_loss: 0.9060 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 87 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_200 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_261 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_201 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_262 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_99  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 111s 4s/step - loss: 0.6997 - acc: 0.6538 - val_loss: 0.7014 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.6882 - acc: 0.7308 - val_loss: 0.6953 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.6869 - acc: 0.6538 - val_loss: 0.6976 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6715 - acc: 0.7692 - val_loss: 0.7063 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.6679 - acc: 0.6538 - val_loss: 0.6917 - val_acc: 0.5714\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 88 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_202 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_263 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_203 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_264 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_100 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 115s 4s/step - loss: 0.7010 - acc: 0.6538 - val_loss: 1.0715 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.7024 - acc: 0.6538 - val_loss: 0.6104 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6561 - acc: 0.7308 - val_loss: 0.6230 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.6342 - acc: 0.7308 - val_loss: 0.6293 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6161 - acc: 0.6923 - val_loss: 0.7602 - val_acc: 0.4286\n",
      "Accuracy 0.13333333333333333\n",
      "F1-score [0.13333333 0.13333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.09      0.13        11\n",
      "           1       0.09      0.25      0.13         4\n",
      "\n",
      "    accuracy                           0.13        15\n",
      "   macro avg       0.17      0.17      0.13        15\n",
      "weighted avg       0.21      0.13      0.13        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 1 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 89 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_204 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_265 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_205 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_101 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 114s 4s/step - loss: 0.7165 - acc: 0.5769 - val_loss: 0.9032 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.7044 - acc: 0.5769 - val_loss: 0.9168 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6656 - acc: 0.6923 - val_loss: 0.6626 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6187 - acc: 0.6923 - val_loss: 0.6619 - val_acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.5873 - acc: 0.6154 - val_loss: 0.7027 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 90 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_206 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_267 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_207 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_268 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_102 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 114s 4s/step - loss: 0.7425 - acc: 0.4615 - val_loss: 2.4711 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6802 - acc: 0.7308 - val_loss: 1.5124 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6999 - acc: 0.6538 - val_loss: 1.1745 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.6574 - acc: 0.7308 - val_loss: 0.9524 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6484 - acc: 0.7308 - val_loss: 0.8543 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 91 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_208 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_269 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_209 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_270 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_103 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 112s 4s/step - loss: 0.7083 - acc: 0.2692 - val_loss: 0.9709 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6952 - acc: 0.6538 - val_loss: 0.6058 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6608 - acc: 0.7308 - val_loss: 1.3242 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.6329 - acc: 0.7308 - val_loss: 2.1577 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.6170 - acc: 0.7308 - val_loss: 1.6999 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 92 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_210 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_271 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_211 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_272 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_104 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 116s 4s/step - loss: 0.6864 - acc: 0.7308 - val_loss: 0.6420 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6568 - acc: 0.7308 - val_loss: 0.6199 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6501 - acc: 0.7308 - val_loss: 0.6028 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6272 - acc: 0.7308 - val_loss: 0.6639 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.6485 - acc: 0.7308 - val_loss: 0.6765 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 93 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_212 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_273 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_213 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_274 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_105 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 123s 5s/step - loss: 0.6843 - acc: 0.6538 - val_loss: 1.1903 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.6804 - acc: 0.6154 - val_loss: 0.8928 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6473 - acc: 0.7308 - val_loss: 0.7789 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.6339 - acc: 0.7308 - val_loss: 0.7616 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.6156 - acc: 0.7308 - val_loss: 0.6989 - val_acc: 0.5714\n",
      "Accuracy 0.6666666666666666\n",
      "F1-score [0.70588235 0.61538462]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        11\n",
      "           1       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.72      0.77      0.66        15\n",
      "weighted avg       0.85      0.67      0.68        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 94 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_214 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_275 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_215 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_276 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_106 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 118s 5s/step - loss: 0.7072 - acc: 0.6538 - val_loss: 0.6828 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6745 - acc: 0.7308 - val_loss: 0.7522 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6698 - acc: 0.7308 - val_loss: 0.6958 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6548 - acc: 0.7308 - val_loss: 0.6647 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6360 - acc: 0.7308 - val_loss: 0.6527 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 6ms/step\n",
      "============================================ 95 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_216 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_277 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_217 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_107 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 131s 5s/step - loss: 0.7183 - acc: 0.5769 - val_loss: 0.6787 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.6996 - acc: 0.5000 - val_loss: 0.8238 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6564 - acc: 0.7308 - val_loss: 0.6353 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.6488 - acc: 0.7308 - val_loss: 0.6322 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6423 - acc: 0.7308 - val_loss: 0.6308 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 5ms/step\n",
      "============================================ 96 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_218 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_219 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_280 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_108 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 122s 5s/step - loss: 0.7039 - acc: 0.6923 - val_loss: 1.6319 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 0.6648 - acc: 0.7308 - val_loss: 0.6911 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.6613 - acc: 0.5769 - val_loss: 0.7072 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6428 - acc: 0.6154 - val_loss: 0.8554 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.5734 - acc: 0.7308 - val_loss: 0.6595 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 97 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_220 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_281 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_221 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_282 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_109 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 126s 5s/step - loss: 0.7325 - acc: 0.6154 - val_loss: 2.2080 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6763 - acc: 0.7308 - val_loss: 0.7765 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.6727 - acc: 0.6923 - val_loss: 0.7494 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 0.6497 - acc: 0.6923 - val_loss: 0.8305 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 0.6276 - acc: 0.7308 - val_loss: 0.7872 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 98 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_222 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_283 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_223 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_284 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_110 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 137s 5s/step - loss: 0.7430 - acc: 0.5000 - val_loss: 1.8490 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.6858 - acc: 0.6923 - val_loss: 1.4722 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 0.7155 - acc: 0.5769 - val_loss: 0.9684 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6846 - acc: 0.6923 - val_loss: 0.6996 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6620 - acc: 0.6923 - val_loss: 0.7013 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 99 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_224 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_285 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_225 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_286 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_111 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 132s 5s/step - loss: 0.6889 - acc: 0.6154 - val_loss: 0.7889 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6649 - acc: 0.6923 - val_loss: 0.8282 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6413 - acc: 0.7692 - val_loss: 0.8140 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 0.6134 - acc: 0.6923 - val_loss: 0.8149 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.5678 - acc: 0.7308 - val_loss: 0.8651 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "for i in range(100):\n",
    "    print('============================================', i, '=============================================================')\n",
    "    X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train, random_state = i)\n",
    "\n",
    "    n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "    print(\"TIMESTEPS: \", n_timesteps)\n",
    "    print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "    cnn = build_simple_cnn(n_timesteps, n_outputs)\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01)\n",
    "    mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    callbacks = [rlr, mc]\n",
    "\n",
    "    batch_size = 16\n",
    "    mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "    history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history\n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "    print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 0 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_250 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_278 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_311 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_251 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_279 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_312 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_126 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 151s 6s/step - loss: 0.6559 - acc: 0.7308 - val_loss: 0.7484 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.6722 - acc: 0.7308 - val_loss: 0.8228 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6334 - acc: 0.7308 - val_loss: 0.8445 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6057 - acc: 0.7308 - val_loss: 0.8477 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.5685 - acc: 0.7308 - val_loss: 0.8428 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 1 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_252 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_253 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_127 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 152s 6s/step - loss: 0.7298 - acc: 0.5769 - val_loss: 0.6957 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.7057 - acc: 0.6154 - val_loss: 0.6883 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.6889 - acc: 0.5769 - val_loss: 0.6806 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.6891 - acc: 0.6538 - val_loss: 0.6583 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6822 - acc: 0.7308 - val_loss: 0.6371 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 2 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_254 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_282 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_315 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_255 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_283 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_316 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_128 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 161s 6s/step - loss: 0.7060 - acc: 0.5000 - val_loss: 0.6736 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6945 - acc: 0.5769 - val_loss: 0.6529 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.6707 - acc: 0.6923 - val_loss: 0.6544 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.6703 - acc: 0.7308 - val_loss: 0.6729 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6642 - acc: 0.7308 - val_loss: 0.7110 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 3 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_256 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_284 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_317 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_257 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_285 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_129 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 155s 6s/step - loss: 0.7023 - acc: 0.5769 - val_loss: 0.6990 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6807 - acc: 0.6538 - val_loss: 0.6975 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.6494 - acc: 0.7308 - val_loss: 0.6979 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.6191 - acc: 0.6538 - val_loss: 0.7492 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.5874 - acc: 0.6154 - val_loss: 0.7274 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 4 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_258 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_286 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_319 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_259 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_287 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_320 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_130 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 161s 6s/step - loss: 0.7348 - acc: 0.6538 - val_loss: 1.1477 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.6846 - acc: 0.5769 - val_loss: 0.8242 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.6493 - acc: 0.7308 - val_loss: 0.8811 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.6321 - acc: 0.7308 - val_loss: 0.7228 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 61ms/step - loss: 0.6030 - acc: 0.7308 - val_loss: 0.7251 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 5 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_260 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_288 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_321 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_261 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_289 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_322 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_131 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 157s 6s/step - loss: 0.7472 - acc: 0.5000 - val_loss: 1.5367 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.7331 - acc: 0.5769 - val_loss: 0.9297 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6980 - acc: 0.6538 - val_loss: 0.8863 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6676 - acc: 0.6923 - val_loss: 0.9669 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.6914 - acc: 0.6923 - val_loss: 0.9411 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 6 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_262 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_290 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_323 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_263 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_291 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_324 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_132 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.7049 - acc: 0.7308 - val_loss: 0.7452 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.6832 - acc: 0.7308 - val_loss: 0.6776 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 0.6797 - acc: 0.7308 - val_loss: 0.7488 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.6823 - acc: 0.7308 - val_loss: 1.0578 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 0.6627 - acc: 0.7308 - val_loss: 0.7544 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n",
      "============================================ 7 =============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_264 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_292 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_325 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_265 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_293 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_133 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 159s 6s/step - loss: 0.6529 - acc: 0.7308 - val_loss: 1.0598 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6508 - acc: 0.7308 - val_loss: 0.7385 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6360 - acc: 0.7308 - val_loss: 0.6462 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6260 - acc: 0.7308 - val_loss: 0.6959 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6175 - acc: 0.7308 - val_loss: 0.6539 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 8 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_266 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_294 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_267 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_295 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_328 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_134 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 175s 7s/step - loss: 0.7522 - acc: 0.5385 - val_loss: 1.4672 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.7052 - acc: 0.5769 - val_loss: 0.7750 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.6591 - acc: 0.6923 - val_loss: 0.8953 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.6275 - acc: 0.7308 - val_loss: 0.9650 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6360 - acc: 0.7308 - val_loss: 1.1036 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 9 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_268 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_296 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_329 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_269 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_297 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_330 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_135 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.6965 - acc: 0.6538 - val_loss: 0.6673 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.6680 - acc: 0.7692 - val_loss: 0.6719 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 0.6170 - acc: 0.6538 - val_loss: 0.6830 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6221 - acc: 0.6154 - val_loss: 0.6576 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6031 - acc: 0.6538 - val_loss: 0.8634 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 7ms/step\n",
      "============================================ 10 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_270 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_298 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_331 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_271 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_299 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_332 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_136 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 174s 7s/step - loss: 0.7084 - acc: 0.7308 - val_loss: 0.6503 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6896 - acc: 0.6538 - val_loss: 1.1122 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6476 - acc: 0.6538 - val_loss: 0.7135 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.6165 - acc: 0.7308 - val_loss: 0.7031 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.5974 - acc: 0.7308 - val_loss: 0.6866 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.9 0.8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.91      0.85        15\n",
      "weighted avg       0.91      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 0 0 0 1 0 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 11 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_272 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_300 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_333 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_273 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_301 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_334 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_137 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 167s 6s/step - loss: 0.6835 - acc: 0.7308 - val_loss: 0.6808 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6594 - acc: 0.7308 - val_loss: 0.9176 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.6502 - acc: 0.7308 - val_loss: 1.3044 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6262 - acc: 0.7308 - val_loss: 0.7966 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.5490 - acc: 0.7692 - val_loss: 0.9271 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 12 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_274 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_302 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_335 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_275 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_303 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_336 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_138 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.7138 - acc: 0.6923 - val_loss: 0.7039 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.6791 - acc: 0.7308 - val_loss: 0.7251 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 0.6764 - acc: 0.7308 - val_loss: 0.7091 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.6526 - acc: 0.7308 - val_loss: 0.7206 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6517 - acc: 0.7308 - val_loss: 0.6970 - val_acc: 0.2857\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.16666667 0.44444444]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        11\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.64      0.55      0.31        15\n",
      "weighted avg       0.81      0.33      0.24        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 13 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_276 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_304 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_337 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_277 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_305 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_338 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_139 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 172s 7s/step - loss: 0.6641 - acc: 0.6923 - val_loss: 0.8710 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6309 - acc: 0.7308 - val_loss: 1.0306 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6598 - acc: 0.7308 - val_loss: 0.8584 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.7107 - acc: 0.7308 - val_loss: 0.6818 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6398 - acc: 0.7308 - val_loss: 0.6967 - val_acc: 0.2857\n",
      "Accuracy 0.6\n",
      "F1-score [0.625      0.57142857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62        11\n",
      "           1       0.40      1.00      0.57         4\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.70      0.73      0.60        15\n",
      "weighted avg       0.84      0.60      0.61        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 0 0 1 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 8ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_278 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_306 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_339 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_279 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_307 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_340 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_140 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 182s 7s/step - loss: 0.7225 - acc: 0.7308 - val_loss: 0.7904 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6902 - acc: 0.7308 - val_loss: 0.7603 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6642 - acc: 0.7308 - val_loss: 0.7288 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.6352 - acc: 0.7308 - val_loss: 0.6344 - val_acc: 0.7143\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 66ms/step - loss: 0.6427 - acc: 0.7308 - val_loss: 0.6724 - val_acc: 0.8571\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95652174 0.85714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.88      0.91        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 15 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_280 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_308 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_341 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_281 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_309 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_342 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_141 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 175s 7s/step - loss: 0.6735 - acc: 0.6538 - val_loss: 0.7175 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.6577 - acc: 0.7308 - val_loss: 0.7726 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 69ms/step - loss: 0.6162 - acc: 0.6923 - val_loss: 0.7099 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.5909 - acc: 0.6154 - val_loss: 0.7331 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.5513 - acc: 0.7308 - val_loss: 0.7427 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 10ms/step\n",
      "============================================ 16 =============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_282 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_310 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_343 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_283 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_311 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_344 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_142 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 187s 7s/step - loss: 0.6905 - acc: 0.6154 - val_loss: 0.6925 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 68ms/step - loss: 0.6852 - acc: 0.7308 - val_loss: 0.6794 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6621 - acc: 0.7308 - val_loss: 0.6116 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6612 - acc: 0.7308 - val_loss: 0.6218 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.6361 - acc: 0.7308 - val_loss: 0.6737 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 17 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_284 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_312 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_345 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_285 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_313 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_346 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_143 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 191s 7s/step - loss: 0.7048 - acc: 0.6923 - val_loss: 0.6803 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6867 - acc: 0.6538 - val_loss: 0.7679 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6693 - acc: 0.6538 - val_loss: 0.7074 - val_acc: 0.5714\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6482 - acc: 0.7308 - val_loss: 0.6979 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6481 - acc: 0.7308 - val_loss: 0.6969 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 18 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_286 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_314 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_347 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_287 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_315 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_348 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_144 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 197s 8s/step - loss: 0.7271 - acc: 0.6154 - val_loss: 2.1618 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6945 - acc: 0.6154 - val_loss: 0.8618 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 0.7045 - acc: 0.6154 - val_loss: 0.9992 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6610 - acc: 0.7308 - val_loss: 1.4254 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6560 - acc: 0.7692 - val_loss: 1.4246 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 19 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_288 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_316 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_349 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_289 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_317 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_350 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_145 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 182s 7s/step - loss: 0.7257 - acc: 0.5385 - val_loss: 0.7662 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 1.5682 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6964 - acc: 0.7308 - val_loss: 1.0229 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6488 - acc: 0.7308 - val_loss: 0.6660 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.6467 - acc: 0.7308 - val_loss: 0.6813 - val_acc: 0.4286\n",
      "Accuracy 0.6\n",
      "F1-score [0.625      0.57142857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62        11\n",
      "           1       0.40      1.00      0.57         4\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.70      0.73      0.60        15\n",
      "weighted avg       0.84      0.60      0.61        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 20 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_290 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_318 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_351 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_291 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_319 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_352 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_146 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 196s 8s/step - loss: 0.7696 - acc: 0.4615 - val_loss: 0.7059 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.7148 - acc: 0.5000 - val_loss: 0.6270 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6961 - acc: 0.5769 - val_loss: 0.5723 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6701 - acc: 0.7308 - val_loss: 0.6418 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6682 - acc: 0.7308 - val_loss: 0.6481 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 21 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_292 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_320 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_353 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_293 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_321 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_354 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_147 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 194s 7s/step - loss: 0.6916 - acc: 0.6923 - val_loss: 0.8426 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6757 - acc: 0.7308 - val_loss: 1.0232 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 0.6559 - acc: 0.7308 - val_loss: 1.0406 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6408 - acc: 0.7308 - val_loss: 0.8879 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6190 - acc: 0.7308 - val_loss: 0.8040 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 22 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_294 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_322 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_355 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_295 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_323 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_356 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_148 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 199s 8s/step - loss: 0.6895 - acc: 0.4615 - val_loss: 1.9335 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.7269 - acc: 0.7308 - val_loss: 1.1490 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.6780 - acc: 0.7308 - val_loss: 1.1483 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6861 - acc: 0.7308 - val_loss: 0.7306 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6453 - acc: 0.7308 - val_loss: 0.7216 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 23 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_296 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_324 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_357 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_297 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_325 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_358 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_149 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 199s 8s/step - loss: 0.7114 - acc: 0.5000 - val_loss: 0.7265 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 73ms/step - loss: 0.6901 - acc: 0.6538 - val_loss: 1.1041 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6830 - acc: 0.6154 - val_loss: 0.7183 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6636 - acc: 0.7308 - val_loss: 0.9382 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6451 - acc: 0.7308 - val_loss: 0.6838 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 24 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_298 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_326 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_359 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_299 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_327 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_150 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 206s 8s/step - loss: 0.6844 - acc: 0.7308 - val_loss: 0.6710 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6786 - acc: 0.7308 - val_loss: 0.6649 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 0.6701 - acc: 0.7308 - val_loss: 0.7504 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6568 - acc: 0.7308 - val_loss: 0.6630 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6363 - acc: 0.7308 - val_loss: 0.6568 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 25 =============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_300 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_328 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_301 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_329 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_151 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 193s 7s/step - loss: 0.7271 - acc: 0.6154 - val_loss: 0.8555 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6539 - acc: 0.7308 - val_loss: 0.6457 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6753 - acc: 0.7308 - val_loss: 0.8516 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6546 - acc: 0.7308 - val_loss: 0.6887 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6406 - acc: 0.7308 - val_loss: 0.6386 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 26 =============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_302 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_330 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_303 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_331 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_152 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 208s 8s/step - loss: 0.7208 - acc: 0.5000 - val_loss: 0.8156 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6750 - acc: 0.6923 - val_loss: 0.6510 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6837 - acc: 0.6538 - val_loss: 0.7739 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6800 - acc: 0.6923 - val_loss: 0.7966 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6557 - acc: 0.7308 - val_loss: 0.6392 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 10ms/step\n",
      "============================================ 27 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_304 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_332 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_365 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_305 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_333 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_366 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_153 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 204s 8s/step - loss: 0.6931 - acc: 0.7308 - val_loss: 0.6599 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6762 - acc: 0.7308 - val_loss: 0.8368 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6718 - acc: 0.7308 - val_loss: 0.9510 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6601 - acc: 0.7308 - val_loss: 0.8495 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6485 - acc: 0.7308 - val_loss: 0.8004 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 28 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_306 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_334 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_367 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_307 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_335 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_368 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_154 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 212s 8s/step - loss: 0.7112 - acc: 0.6154 - val_loss: 2.2004 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6648 - acc: 0.7308 - val_loss: 1.7395 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6680 - acc: 0.7308 - val_loss: 1.2602 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6613 - acc: 0.7308 - val_loss: 1.5217 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6354 - acc: 0.7308 - val_loss: 1.5897 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 29 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_308 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_336 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_369 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_309 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_337 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_370 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_155 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 208s 8s/step - loss: 0.6718 - acc: 0.7308 - val_loss: 1.2893 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.6549 - acc: 0.7308 - val_loss: 0.8234 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6465 - acc: 0.7308 - val_loss: 0.6907 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6238 - acc: 0.7308 - val_loss: 0.6477 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.5572 - acc: 0.7308 - val_loss: 0.6707 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.90909091 0.75      ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.83      0.83      0.83        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 10ms/step\n",
      "============================================ 30 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_310 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_338 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_371 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_311 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_339 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_372 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_156 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 218s 8s/step - loss: 0.6942 - acc: 0.6923 - val_loss: 0.6480 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.7001 - acc: 0.7308 - val_loss: 0.7828 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6653 - acc: 0.7308 - val_loss: 0.7914 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 0.6200 - acc: 0.7308 - val_loss: 0.8192 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6057 - acc: 0.7308 - val_loss: 0.7186 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 31 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_312 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_340 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_312 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_373 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_313 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_341 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_313 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_374 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_157 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 208s 8s/step - loss: 0.6749 - acc: 0.6154 - val_loss: 1.8340 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6635 - acc: 0.6923 - val_loss: 0.8641 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6280 - acc: 0.7308 - val_loss: 0.7845 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6367 - acc: 0.7308 - val_loss: 0.7343 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 0.6053 - acc: 0.7308 - val_loss: 0.6926 - val_acc: 0.4286\n",
      "Accuracy 0.4666666666666667\n",
      "F1-score [0.42857143 0.5       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43        11\n",
      "           1       0.33      1.00      0.50         4\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.67      0.64      0.46        15\n",
      "weighted avg       0.82      0.47      0.45        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 1 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 10ms/step\n",
      "============================================ 32 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_314 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_342 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_314 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_375 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_315 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_343 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_315 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_376 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_158 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 225s 9s/step - loss: 0.7407 - acc: 0.7308 - val_loss: 0.9141 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 75ms/step - loss: 0.6456 - acc: 0.7692 - val_loss: 0.8892 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6453 - acc: 0.6154 - val_loss: 0.6750 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.5980 - acc: 0.6923 - val_loss: 0.6811 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.5756 - acc: 0.6538 - val_loss: 0.6260 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 33 ============================================================="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_316 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_344 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_316 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_377 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_317 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_345 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_317 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_378 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_159 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 218s 8s/step - loss: 0.6779 - acc: 0.7308 - val_loss: 0.6026 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6641 - acc: 0.7308 - val_loss: 0.6458 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6375 - acc: 0.7308 - val_loss: 0.6160 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.5845 - acc: 0.7308 - val_loss: 0.6292 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.5661 - acc: 0.7308 - val_loss: 0.6565 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 10ms/step\n",
      "============================================ 34 =============================================================\n",
      "TIMESTEPS: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_318 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_346 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_318 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_379 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_319 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_347 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_319 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_380 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_160 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 230s 9s/step - loss: 0.7170 - acc: 0.4231 - val_loss: 0.6911 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.6869 - acc: 0.7308 - val_loss: 0.7223 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.6655 - acc: 0.7308 - val_loss: 0.6452 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6627 - acc: 0.7308 - val_loss: 0.6717 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 0.6301 - acc: 0.6923 - val_loss: 0.6453 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 35 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_320 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_348 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_381 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_321 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_349 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_382 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_161 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 233s 9s/step - loss: 0.7109 - acc: 0.6538 - val_loss: 1.1990 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.6741 - acc: 0.6154 - val_loss: 1.4507 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6317 - acc: 0.6923 - val_loss: 1.3417 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.6047 - acc: 0.7308 - val_loss: 1.8221 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6154 - acc: 0.7308 - val_loss: 1.2334 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 9ms/step\n",
      "============================================ 36 =============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_322 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_350 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_322 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_383 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_323 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_351 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_323 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_384 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_162 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 237s 9s/step - loss: 0.6598 - acc: 0.6154 - val_loss: 1.2626 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.7155 - acc: 0.6923 - val_loss: 1.6809 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6709 - acc: 0.7308 - val_loss: 2.5477 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 74ms/step - loss: 0.6665 - acc: 0.6923 - val_loss: 1.9943 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.6462 - acc: 0.7308 - val_loss: 1.7057 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step\n",
      "============================================ 37 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_324 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_352 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_324 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_385 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_325 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_353 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_325 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_386 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_163 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 224s 9s/step - loss: 0.7086 - acc: 0.5385 - val_loss: 0.7247 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 0.7090 - acc: 0.5000 - val_loss: 1.0470 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.6776 - acc: 0.6923 - val_loss: 0.6779 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6676 - acc: 0.7308 - val_loss: 0.7158 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 0.6486 - acc: 0.7308 - val_loss: 0.6981 - val_acc: 0.1429\n",
      "Accuracy 0.06666666666666667\n",
      "F1-score [0.    0.125]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.08      0.25      0.12         4\n",
      "\n",
      "    accuracy                           0.07        15\n",
      "   macro avg       0.04      0.12      0.06        15\n",
      "weighted avg       0.02      0.07      0.03        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 0 1 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "15/15 [==============================] - 0s 11ms/step\n",
      "============================================ 38 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_326 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_354 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_326 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_387 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_327 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_355 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_327 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_388 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_164 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 239s 9s/step - loss: 0.7035 - acc: 0.3846 - val_loss: 0.6143 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6989 - acc: 0.6923 - val_loss: 0.6271 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6639 - acc: 0.7308 - val_loss: 0.6617 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 77ms/step - loss: 0.6361 - acc: 0.6538 - val_loss: 0.6948 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6216 - acc: 0.6923 - val_loss: 0.6602 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 39 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_328 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_356 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_328 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_389 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_329 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_357 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_329 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_390 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_165 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 233s 9s/step - loss: 0.6912 - acc: 0.6923 - val_loss: 0.6999 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6857 - acc: 0.7308 - val_loss: 0.6548 - val_acc: 0.5714\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6624 - acc: 0.7308 - val_loss: 0.6491 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6478 - acc: 0.7308 - val_loss: 0.6474 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6216 - acc: 0.7308 - val_loss: 0.6492 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 40 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_330 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_358 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_330 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_391 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_331 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_359 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_331 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_392 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_166 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 246s 9s/step - loss: 0.6860 - acc: 0.6154 - val_loss: 1.6165 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6673 - acc: 0.7308 - val_loss: 0.7807 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6465 - acc: 0.7308 - val_loss: 0.7264 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6318 - acc: 0.7308 - val_loss: 0.7327 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.6638 - acc: 0.7308 - val_loss: 0.7367 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step\n",
      "============================================ 41 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_332 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_360 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_332 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_393 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_333 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_361 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_333 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_394 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_167 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 237s 9s/step - loss: 0.7779 - acc: 0.5769 - val_loss: 0.8872 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.7023 - acc: 0.6538 - val_loss: 0.6402 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 0.7083 - acc: 0.5385 - val_loss: 1.1340 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 81ms/step - loss: 0.6612 - acc: 0.7308 - val_loss: 0.8191 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6511 - acc: 0.7308 - val_loss: 0.6394 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 42 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_334 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_362 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_334 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_395 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_335 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_363 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_335 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_396 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_168 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 245s 9s/step - loss: 0.6953 - acc: 0.6538 - val_loss: 1.4346 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6894 - acc: 0.7308 - val_loss: 0.7230 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6662 - acc: 0.7308 - val_loss: 0.6727 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.6453 - acc: 0.7308 - val_loss: 0.6406 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6044 - acc: 0.6923 - val_loss: 0.6583 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.91666667 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.92      0.75      0.79        15\n",
      "weighted avg       0.89      0.87      0.85        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n",
      "============================================ 43 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_336 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_364 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_336 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_397 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_337 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_365 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_337 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_398 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_169 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 248s 10s/step - loss: 0.6977 - acc: 0.5385 - val_loss: 0.7268 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6680 - acc: 0.7308 - val_loss: 0.7579 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.6652 - acc: 0.6538 - val_loss: 0.6584 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.6319 - acc: 0.7308 - val_loss: 0.6922 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.5972 - acc: 0.7308 - val_loss: 0.7180 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 44 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_338 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_366 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_338 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_399 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_339 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_367 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_339 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_400 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_170 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 254s 10s/step - loss: 0.6927 - acc: 0.5385 - val_loss: 0.9968 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6748 - acc: 0.7308 - val_loss: 0.8486 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6387 - acc: 0.7308 - val_loss: 0.9581 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6197 - acc: 0.7308 - val_loss: 0.8926 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6246 - acc: 0.7308 - val_loss: 0.9101 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 45 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_340 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_368 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_340 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_401 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_341 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_369 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_341 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_402 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_171 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 253s 10s/step - loss: 0.7102 - acc: 0.5769 - val_loss: 1.4847 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6748 - acc: 0.7308 - val_loss: 0.9787 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6773 - acc: 0.7308 - val_loss: 0.6526 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6501 - acc: 0.6923 - val_loss: 0.6396 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6150 - acc: 0.7308 - val_loss: 0.6257 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 46 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_342 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_370 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_342 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_403 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_343 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_371 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_343 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_404 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_172 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 262s 10s/step - loss: 0.6562 - acc: 0.7308 - val_loss: 0.6112 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 86ms/step - loss: 0.6450 - acc: 0.7308 - val_loss: 0.6422 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.7261 - acc: 0.7308 - val_loss: 0.6905 - val_acc: 0.5714\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6550 - acc: 0.7308 - val_loss: 0.7017 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6365 - acc: 0.7308 - val_loss: 0.7323 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 47 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_344 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_372 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_344 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_405 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_345 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_373 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_345 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_406 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_173 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 253s 10s/step - loss: 0.6892 - acc: 0.6538 - val_loss: 1.6398 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.6621 - acc: 0.7308 - val_loss: 1.1257 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 105ms/step - loss: 0.6770 - acc: 0.7308 - val_loss: 0.9835 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6155 - acc: 0.7308 - val_loss: 0.8461 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6292 - acc: 0.7308 - val_loss: 0.8497 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_346 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_374 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_346 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_407 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_347 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_375 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_347 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_408 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_174 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 268s 10s/step - loss: 0.7059 - acc: 0.6923 - val_loss: 0.6511 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6678 - acc: 0.6154 - val_loss: 0.6491 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6237 - acc: 0.6538 - val_loss: 0.6689 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.5640 - acc: 0.7692 - val_loss: 0.6630 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6338 - acc: 0.5769 - val_loss: 0.6736 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 49 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_348 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_376 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_348 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_409 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_349 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_377 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_349 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_410 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_175 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 270s 10s/step - loss: 0.6643 - acc: 0.4615 - val_loss: 1.0152 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6890 - acc: 0.6923 - val_loss: 0.6680 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6856 - acc: 0.7308 - val_loss: 0.9481 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6538 - acc: 0.7308 - val_loss: 1.2224 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6534 - acc: 0.7308 - val_loss: 1.7835 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 50 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_350 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_378 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_350 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_411 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_351 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_379 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_351 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_412 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_176 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 273s 10s/step - loss: 0.7238 - acc: 0.4615 - val_loss: 0.6961 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6831 - acc: 0.6154 - val_loss: 0.6542 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6730 - acc: 0.6154 - val_loss: 0.6230 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6382 - acc: 0.7308 - val_loss: 0.6523 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 82ms/step - loss: 0.6266 - acc: 0.7308 - val_loss: 0.6601 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 51 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_352 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_380 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_352 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_413 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_353 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_381 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_353 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_414 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_177 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 263s 10s/step - loss: 0.6894 - acc: 0.7308 - val_loss: 2.4644 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6637 - acc: 0.7308 - val_loss: 1.5579 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.7023 - acc: 0.5769 - val_loss: 1.0791 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6483 - acc: 0.7308 - val_loss: 0.8017 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6394 - acc: 0.7308 - val_loss: 0.8459 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 52 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_354 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_382 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_354 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_415 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_355 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_383 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_355 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_416 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_178 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 278s 11s/step - loss: 0.7428 - acc: 0.6538 - val_loss: 0.6543 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.6753 - acc: 0.7308 - val_loss: 0.8501 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 80ms/step - loss: 0.6826 - acc: 0.7308 - val_loss: 1.0939 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6516 - acc: 0.7308 - val_loss: 0.8816 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6354 - acc: 0.7308 - val_loss: 0.8088 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 53 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_356 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_384 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_356 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_417 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_357 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_385 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_357 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_418 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_179 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 265s 10s/step - loss: 0.7326 - acc: 0.3846 - val_loss: 0.7576 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.6941 - acc: 0.6923 - val_loss: 0.6841 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.6754 - acc: 0.7308 - val_loss: 0.6716 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6543 - acc: 0.7308 - val_loss: 0.6723 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6486 - acc: 0.6538 - val_loss: 0.6965 - val_acc: 0.4286\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 12ms/step\n",
      "============================================ 54 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_358 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_386 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_358 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_419 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_359 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_387 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_359 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_420 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_180 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 288s 11s/step - loss: 0.7324 - acc: 0.6538 - val_loss: 0.9805 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6884 - acc: 0.7308 - val_loss: 1.6847 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6679 - acc: 0.7692 - val_loss: 0.6406 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6574 - acc: 0.7308 - val_loss: 0.6666 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.6413 - acc: 0.7308 - val_loss: 0.6860 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step\n",
      "============================================ 55 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_360 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_388 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_360 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_421 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_361 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_389 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_361 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_422 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_181 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 273s 10s/step - loss: 0.7030 - acc: 0.5000 - val_loss: 1.7032 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6872 - acc: 0.6923 - val_loss: 0.8015 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6716 - acc: 0.7308 - val_loss: 0.7099 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.6526 - acc: 0.7308 - val_loss: 0.7487 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6404 - acc: 0.7308 - val_loss: 0.7790 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 56 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_362 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_390 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_362 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_423 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_363 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_391 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_363 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_424 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_182 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 286s 11s/step - loss: 0.7687 - acc: 0.6154 - val_loss: 0.7958 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.7396 - acc: 0.6154 - val_loss: 0.6971 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6916 - acc: 0.6538 - val_loss: 0.6651 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6645 - acc: 0.7308 - val_loss: 0.6325 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6666 - acc: 0.7308 - val_loss: 0.5887 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 57 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_364 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_392 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_364 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_425 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_365 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_393 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_365 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_426 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_183 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 275s 11s/step - loss: 0.6904 - acc: 0.6923 - val_loss: 0.6845 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6743 - acc: 0.6538 - val_loss: 0.6864 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6481 - acc: 0.7692 - val_loss: 0.6540 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6371 - acc: 0.7308 - val_loss: 0.6291 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.5856 - acc: 0.7308 - val_loss: 0.6301 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 58 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_366 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_394 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_366 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_427 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_367 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_395 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_367 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_428 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_184 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 291s 11s/step - loss: 0.6986 - acc: 0.6538 - val_loss: 0.6727 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 85ms/step - loss: 0.6788 - acc: 0.7308 - val_loss: 0.9282 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 84ms/step - loss: 0.6631 - acc: 0.7308 - val_loss: 0.8525 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6361 - acc: 0.7308 - val_loss: 0.7409 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 83ms/step - loss: 0.5915 - acc: 0.7308 - val_loss: 0.7298 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 59 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_368 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_396 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_368 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_429 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_369 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_397 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_369 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_430 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_185 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 278s 11s/step - loss: 0.7159 - acc: 0.7308 - val_loss: 1.1566 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6925 - acc: 0.7308 - val_loss: 0.6395 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6570 - acc: 0.7308 - val_loss: 0.8448 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 0.8772 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6470 - acc: 0.7308 - val_loss: 0.7878 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 60 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_370 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_398 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_370 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_431 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_371 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_399 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_371 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_432 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_186 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 298s 11s/step - loss: 0.7032 - acc: 0.6538 - val_loss: 1.4912 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.6900 - acc: 0.5385 - val_loss: 0.6640 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6745 - acc: 0.7692 - val_loss: 0.6384 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6562 - acc: 0.6538 - val_loss: 0.7490 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6372 - acc: 0.7308 - val_loss: 0.6646 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 61 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_372 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_400 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_372 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_433 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_373 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_401 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_373 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_434 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_187 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 285s 11s/step - loss: 0.6739 - acc: 0.6538 - val_loss: 0.8765 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6876 - acc: 0.7308 - val_loss: 1.4855 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.7454 - acc: 0.7308 - val_loss: 0.7068 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 105ms/step - loss: 0.6843 - acc: 0.7308 - val_loss: 0.6968 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6484 - acc: 0.6923 - val_loss: 0.7722 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 62 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_374 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_402 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_374 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_435 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_375 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_403 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_375 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_436 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_188 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 301s 12s/step - loss: 0.7225 - acc: 0.3462 - val_loss: 0.9724 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6930 - acc: 0.6923 - val_loss: 0.8314 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6765 - acc: 0.6538 - val_loss: 0.8598 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6965 - acc: 0.6923 - val_loss: 0.6213 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6577 - acc: 0.7308 - val_loss: 0.6296 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 63 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_376 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_404 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_376 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_437 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_377 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_405 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_377 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_438 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_189 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 290s 11s/step - loss: 0.6974 - acc: 0.5769 - val_loss: 0.6889 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6735 - acc: 0.7308 - val_loss: 0.6611 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.7049 - acc: 0.7308 - val_loss: 0.6649 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6688 - acc: 0.7308 - val_loss: 0.7158 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6478 - acc: 0.7308 - val_loss: 0.7024 - val_acc: 0.4286\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 64 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_378 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_406 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_378 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_439 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_379 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_407 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_379 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_440 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_190 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 306s 12s/step - loss: 0.7275 - acc: 0.6154 - val_loss: 0.7937 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6669 - acc: 0.7308 - val_loss: 0.7692 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 0.6578 - acc: 0.5769 - val_loss: 0.7421 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.6220 - acc: 0.7308 - val_loss: 0.7135 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.5990 - acc: 0.7308 - val_loss: 0.7019 - val_acc: 0.1429\n",
      "Accuracy 0.06666666666666667\n",
      "F1-score [0.125 0.   ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.09      0.13        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.07        15\n",
      "   macro avg       0.10      0.05      0.06        15\n",
      "weighted avg       0.15      0.07      0.09        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 1 1 1 1 1 0 1 1 1 1 0 1]\n",
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 65 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_380 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_408 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_380 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_441 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_381 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_409 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_442 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_191 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 291s 11s/step - loss: 0.7057 - acc: 0.7308 - val_loss: 0.7446 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6690 - acc: 0.7308 - val_loss: 0.8270 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6603 - acc: 0.6538 - val_loss: 0.7408 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 0.6320 - acc: 0.6154 - val_loss: 0.7253 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6164 - acc: 0.7308 - val_loss: 0.6999 - val_acc: 0.4286\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 66 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_382 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_410 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_382 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_443 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_383 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_411 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_383 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_444 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_192 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 319s 12s/step - loss: 0.7356 - acc: 0.5769 - val_loss: 0.8772 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6995 - acc: 0.6538 - val_loss: 0.7303 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.6847 - acc: 0.6923 - val_loss: 0.6847 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6720 - acc: 0.7308 - val_loss: 0.6435 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6613 - acc: 0.7308 - val_loss: 0.6842 - val_acc: 0.7143\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95238095 0.88888889]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.90      0.95      0.92        15\n",
      "weighted avg       0.95      0.93      0.94        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 67 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_384 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_412 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_384 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_445 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_385 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_413 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_385 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_446 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_193 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 295s 11s/step - loss: 0.7473 - acc: 0.5385 - val_loss: 1.4869 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6868 - acc: 0.6923 - val_loss: 0.9674 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6774 - acc: 0.5385 - val_loss: 1.5185 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6207 - acc: 0.7308 - val_loss: 1.6227 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6362 - acc: 0.7308 - val_loss: 1.7955 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 68 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_386 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_414 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_386 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_447 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_387 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_415 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_387 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_448 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_194 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 315s 12s/step - loss: 0.7165 - acc: 0.5000 - val_loss: 0.7838 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6806 - acc: 0.6923 - val_loss: 0.7082 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6590 - acc: 0.7308 - val_loss: 0.6279 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 0.6942 - acc: 0.7308 - val_loss: 0.6496 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 2s 89ms/step - loss: 0.6652 - acc: 0.7308 - val_loss: 0.6659 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 69 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_388 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_416 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_388 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_449 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_389 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_417 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_389 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_450 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_195 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 302s 12s/step - loss: 0.7094 - acc: 0.3077 - val_loss: 0.7107 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6992 - acc: 0.7308 - val_loss: 0.6725 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6766 - acc: 0.6923 - val_loss: 0.6665 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6606 - acc: 0.7308 - val_loss: 0.6967 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6558 - acc: 0.7308 - val_loss: 0.7019 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 70 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_390 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_418 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_390 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_451 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_391 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_419 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_391 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_452 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_196 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 315s 12s/step - loss: 0.6737 - acc: 0.7308 - val_loss: 0.6264 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 92ms/step - loss: 0.6456 - acc: 0.7308 - val_loss: 0.6672 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.5913 - acc: 0.7308 - val_loss: 0.7285 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6052 - acc: 0.6538 - val_loss: 0.7263 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.4993 - acc: 0.7308 - val_loss: 0.7434 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 71 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_392 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_420 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_392 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_453 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_393 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_421 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_393 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_454 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_197 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 312s 12s/step - loss: 0.6894 - acc: 0.6154 - val_loss: 0.6916 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 2s 94ms/step - loss: 0.6577 - acc: 0.7308 - val_loss: 0.7052 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6461 - acc: 0.7308 - val_loss: 0.6819 - val_acc: 0.4286\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.6268 - acc: 0.7308 - val_loss: 0.7045 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6197 - acc: 0.7308 - val_loss: 0.6425 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 14ms/step\n",
      "============================================ 72 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_394 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_422 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_394 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_455 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_395 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_423 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_395 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_456 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_198 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 320s 12s/step - loss: 0.6989 - acc: 0.5385 - val_loss: 1.1475 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.6676 - acc: 0.8077 - val_loss: 1.0431 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6449 - acc: 0.7308 - val_loss: 1.6415 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 0.6393 - acc: 0.6923 - val_loss: 1.4881 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6559 - acc: 0.6923 - val_loss: 1.2099 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 73 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_396 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_424 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_396 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_457 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_397 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_425 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_397 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_458 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_199 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 323s 12s/step - loss: 0.6956 - acc: 0.6538 - val_loss: 0.6994 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6704 - acc: 0.6923 - val_loss: 0.7699 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6498 - acc: 0.6923 - val_loss: 0.7195 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 102ms/step - loss: 0.6331 - acc: 0.6923 - val_loss: 0.6587 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6096 - acc: 0.7308 - val_loss: 0.6726 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 74 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_398 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_426 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_398 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_459 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_399 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_427 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_399 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_460 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_200 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 328s 13s/step - loss: 0.7021 - acc: 0.5769 - val_loss: 0.6822 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6942 - acc: 0.7308 - val_loss: 0.6634 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6808 - acc: 0.6923 - val_loss: 0.6793 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6596 - acc: 0.7308 - val_loss: 0.6622 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6672 - acc: 0.7308 - val_loss: 0.6246 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 75 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_400 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_428 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_400 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_461 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_401 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_429 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_401 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_462 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_201 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 322s 12s/step - loss: 0.7378 - acc: 0.5385 - val_loss: 0.6914 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 105ms/step - loss: 0.6953 - acc: 0.5769 - val_loss: 0.6872 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6572 - acc: 0.6538 - val_loss: 0.6741 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6261 - acc: 0.6923 - val_loss: 0.6775 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6207 - acc: 0.7308 - val_loss: 0.6750 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 76 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_402 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_430 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_402 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_463 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_403 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_431 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_403 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_464 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_202 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 332s 13s/step - loss: 0.6973 - acc: 0.6923 - val_loss: 0.8528 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6732 - acc: 0.7692 - val_loss: 0.7093 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6742 - acc: 0.6923 - val_loss: 0.8954 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 2s 95ms/step - loss: 0.6866 - acc: 0.6538 - val_loss: 0.7338 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6349 - acc: 0.7308 - val_loss: 0.6610 - val_acc: 0.8571\n",
      "Accuracy 0.8\n",
      "F1-score [0.85714286 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        11\n",
      "           1       0.60      0.75      0.67         4\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.75      0.78      0.76        15\n",
      "weighted avg       0.82      0.80      0.81        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 0 0 0 0 0 1 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 77 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_404 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_432 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_404 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_465 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_405 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_433 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_405 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_466 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_203 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 322s 12s/step - loss: 0.7202 - acc: 0.4615 - val_loss: 0.6760 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 96ms/step - loss: 0.6971 - acc: 0.6923 - val_loss: 1.1795 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6754 - acc: 0.7308 - val_loss: 0.7857 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.6542 - acc: 0.7308 - val_loss: 0.7829 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6518 - acc: 0.7308 - val_loss: 0.7131 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step\n",
      "============================================ 78 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_406 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_434 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_406 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_467 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_407 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_435 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_407 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_468 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_204 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 338s 13s/step - loss: 0.7065 - acc: 0.6154 - val_loss: 0.8160 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.7134 - acc: 0.4615 - val_loss: 0.6850 - val_acc: 0.8571\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6775 - acc: 0.7308 - val_loss: 0.6901 - val_acc: 0.4286\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6708 - acc: 0.6923 - val_loss: 0.6937 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6545 - acc: 0.7308 - val_loss: 0.6481 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 79 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_408 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_436 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_408 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_469 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_409 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_437 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_409 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_470 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_205 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 339s 13s/step - loss: 0.7142 - acc: 0.5769 - val_loss: 2.9606 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6996 - acc: 0.4615 - val_loss: 1.5537 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6695 - acc: 0.6923 - val_loss: 0.9343 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 0.6563 - acc: 0.6538 - val_loss: 1.0279 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.6434 - acc: 0.7308 - val_loss: 1.1375 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 80 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_410 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_438 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_410 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_471 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_411 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_439 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_411 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_472 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_206 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 357s 14s/step - loss: 0.6956 - acc: 0.7308 - val_loss: 3.6041 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 111ms/step - loss: 0.6825 - acc: 0.7308 - val_loss: 1.1096 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6679 - acc: 0.7308 - val_loss: 0.9626 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.6508 - acc: 0.7308 - val_loss: 0.8722 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6351 - acc: 0.7308 - val_loss: 0.8973 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 81 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_412 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_440 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_412 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_473 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_413 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_441 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_413 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_474 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_207 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 337s 13s/step - loss: 0.7086 - acc: 0.5385 - val_loss: 1.3129 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6811 - acc: 0.6923 - val_loss: 0.9302 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6632 - acc: 0.6923 - val_loss: 0.9675 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6519 - acc: 0.7308 - val_loss: 0.8519 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 0.6708 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.91666667 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.92      0.75      0.79        15\n",
      "weighted avg       0.89      0.87      0.85        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 82 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_414 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_442 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_414 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_475 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_415 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_443 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_415 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_476 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_208 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 347s 13s/step - loss: 0.7313 - acc: 0.6538 - val_loss: 0.6871 - val_acc: 0.4286\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.7004 - acc: 0.5769 - val_loss: 0.9210 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2s 96ms/step - loss: 0.6537 - acc: 0.7308 - val_loss: 0.9583 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 107ms/step - loss: 0.6600 - acc: 0.7308 - val_loss: 0.6810 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6232 - acc: 0.7308 - val_loss: 0.6660 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 83 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_416 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_444 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_416 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_477 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_417 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_445 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_417 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_478 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_209 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 345s 13s/step - loss: 0.6726 - acc: 0.7308 - val_loss: 1.4428 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 109ms/step - loss: 0.6623 - acc: 0.7308 - val_loss: 0.6798 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6392 - acc: 0.7308 - val_loss: 0.8040 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.6180 - acc: 0.6923 - val_loss: 0.9372 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 98ms/step - loss: 0.5880 - acc: 0.6923 - val_loss: 0.9333 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 16ms/step\n",
      "============================================ 84 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_418 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_446 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_418 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_479 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_419 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_447 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_419 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_480 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_210 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 349s 13s/step - loss: 0.7367 - acc: 0.5385 - val_loss: 0.6705 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 105ms/step - loss: 0.7114 - acc: 0.5769 - val_loss: 1.6012 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.6795 - acc: 0.7308 - val_loss: 1.7057 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6578 - acc: 0.6923 - val_loss: 1.2011 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 99ms/step - loss: 0.6476 - acc: 0.7308 - val_loss: 0.9714 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 85 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_420 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_448 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_420 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_481 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_421 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_449 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_421 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_482 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_211 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 349s 13s/step - loss: 0.6878 - acc: 0.7308 - val_loss: 1.3744 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 109ms/step - loss: 0.6762 - acc: 0.7308 - val_loss: 1.0276 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6761 - acc: 0.7308 - val_loss: 0.6788 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6530 - acc: 0.7308 - val_loss: 0.7255 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6391 - acc: 0.7308 - val_loss: 0.6944 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 86 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_422 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_450 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_422 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_483 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_423 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_451 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_423 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_484 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_212 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 355s 14s/step - loss: 0.7192 - acc: 0.5769 - val_loss: 1.1424 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.6775 - acc: 0.7692 - val_loss: 1.2124 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 109ms/step - loss: 0.6762 - acc: 0.7692 - val_loss: 0.7263 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6477 - acc: 0.8077 - val_loss: 0.6925 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6288 - acc: 0.7692 - val_loss: 0.6778 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step\n",
      "============================================ 87 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_424 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_452 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_424 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_485 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_425 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_453 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_425 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_486 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_213 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 356s 14s/step - loss: 0.7625 - acc: 0.3846 - val_loss: 0.7579 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.6862 - acc: 0.7308 - val_loss: 0.6283 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6701 - acc: 0.6923 - val_loss: 0.6432 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6908 - acc: 0.6923 - val_loss: 0.6420 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 101ms/step - loss: 0.6837 - acc: 0.6923 - val_loss: 0.7110 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 88 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_426 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_454 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_426 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_487 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_427 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_455 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_427 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_488 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_214 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 364s 14s/step - loss: 0.7073 - acc: 0.5769 - val_loss: 3.0440 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6715 - acc: 0.7308 - val_loss: 1.9795 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6406 - acc: 0.7308 - val_loss: 1.7033 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6325 - acc: 0.7308 - val_loss: 0.8015 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.5724 - acc: 0.7308 - val_loss: 0.7104 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 17ms/step\n",
      "============================================ 89 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_428 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_456 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_428 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_489 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_429 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_457 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_429 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_490 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_215 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 358s 14s/step - loss: 0.7015 - acc: 0.6923 - val_loss: 0.8720 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 111ms/step - loss: 0.6841 - acc: 0.7308 - val_loss: 0.8326 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6702 - acc: 0.7308 - val_loss: 0.7572 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6677 - acc: 0.7308 - val_loss: 0.6625 - val_acc: 0.8571\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6400 - acc: 0.7308 - val_loss: 0.6911 - val_acc: 0.4286\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 90 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_430 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_458 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_430 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_491 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_431 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_459 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_431 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_492 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_216 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 370s 14s/step - loss: 0.6896 - acc: 0.6538 - val_loss: 0.6840 - val_acc: 0.5714\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 0.6764 - acc: 0.7308 - val_loss: 0.6802 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6411 - acc: 0.7308 - val_loss: 0.6835 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6307 - acc: 0.7308 - val_loss: 0.6820 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.5848 - acc: 0.7308 - val_loss: 0.7294 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step\n",
      "============================================ 91 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_432 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_460 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_432 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_493 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_433 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_461 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_433 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_494 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_217 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 367s 14s/step - loss: 0.7015 - acc: 0.7308 - val_loss: 1.4792 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6959 - acc: 0.7308 - val_loss: 0.9253 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6762 - acc: 0.7308 - val_loss: 0.6706 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6490 - acc: 0.7308 - val_loss: 0.6871 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6335 - acc: 0.7308 - val_loss: 0.6779 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 92 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_434 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_462 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_434 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_495 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_435 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_463 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_435 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_496 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_218 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 372s 14s/step - loss: 0.6783 - acc: 0.7308 - val_loss: 0.6921 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 109ms/step - loss: 0.6474 - acc: 0.7308 - val_loss: 0.8182 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.6104 - acc: 0.6923 - val_loss: 0.8682 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 108ms/step - loss: 0.6297 - acc: 0.5769 - val_loss: 0.9110 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 104ms/step - loss: 0.6012 - acc: 0.6154 - val_loss: 0.7391 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 93 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_436 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_464 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_436 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_497 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_437 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_465 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_437 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_498 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_219 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 377s 15s/step - loss: 0.7154 - acc: 0.5385 - val_loss: 0.7251 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6875 - acc: 0.7308 - val_loss: 0.7205 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6711 - acc: 0.7308 - val_loss: 0.7168 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.6729 - acc: 0.7308 - val_loss: 0.6915 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6230 - acc: 0.7308 - val_loss: 0.7322 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step\n",
      "============================================ 94 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_438 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_466 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_438 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_499 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_439 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_467 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_439 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_500 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_220 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 382s 15s/step - loss: 0.7104 - acc: 0.5769 - val_loss: 0.7074 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6695 - acc: 0.7308 - val_loss: 0.6322 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6364 - acc: 0.7308 - val_loss: 0.6379 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.6243 - acc: 0.7308 - val_loss: 0.6424 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.5931 - acc: 0.6923 - val_loss: 0.6336 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 95 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_440 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_468 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_440 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_501 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_441 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_469 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_441 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_502 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_221 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 380s 15s/step - loss: 0.7343 - acc: 0.5769 - val_loss: 1.0382 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 111ms/step - loss: 0.6852 - acc: 0.6538 - val_loss: 0.8315 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6764 - acc: 0.6154 - val_loss: 0.7411 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6567 - acc: 0.7308 - val_loss: 0.6657 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6427 - acc: 0.7308 - val_loss: 0.6733 - val_acc: 0.7143\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95238095 0.88888889]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.90      0.95      0.92        15\n",
      "weighted avg       0.95      0.93      0.94        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 96 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_442 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_470 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_442 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_503 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_443 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_471 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_443 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_504 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_222 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 388s 15s/step - loss: 0.7017 - acc: 0.6538 - val_loss: 0.6649 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6775 - acc: 0.7308 - val_loss: 0.6420 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6734 - acc: 0.7308 - val_loss: 0.6249 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6494 - acc: 0.7308 - val_loss: 0.6625 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6336 - acc: 0.7308 - val_loss: 0.6761 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step\n",
      "============================================ 97 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_444 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_472 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_444 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_505 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_445 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_473 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_445 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_506 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_223 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 386s 15s/step - loss: 0.7325 - acc: 0.4615 - val_loss: 0.7145 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6906 - acc: 0.6154 - val_loss: 0.6559 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6619 - acc: 0.7308 - val_loss: 0.7432 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6411 - acc: 0.7308 - val_loss: 0.6838 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 0.6337 - acc: 0.6538 - val_loss: 0.5859 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 98 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_446 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_474 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_446 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_507 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_447 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_475 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_447 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_508 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_224 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 392s 15s/step - loss: 0.7095 - acc: 0.5769 - val_loss: 0.6654 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 0.6755 - acc: 0.7308 - val_loss: 1.0126 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6633 - acc: 0.7308 - val_loss: 0.9550 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.6544 - acc: 0.7308 - val_loss: 1.0766 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6433 - acc: 0.7308 - val_loss: 0.8128 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 99 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_448 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_476 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_448 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_509 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_449 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_477 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_449 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_510 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_225 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 394s 15s/step - loss: 0.7221 - acc: 0.4615 - val_loss: 0.7198 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6919 - acc: 0.6154 - val_loss: 0.6128 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6834 - acc: 0.6923 - val_loss: 0.6480 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6798 - acc: 0.6538 - val_loss: 0.6327 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 106ms/step - loss: 0.6706 - acc: 0.7308 - val_loss: 0.6378 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "15/15 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs, i):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = i)) #EUREKA!!!!\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D()) #non ha random state\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid')) #Dense non ha random state\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #.compile non ha random state\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print('============================================', i, '=============================================================')\n",
    "    X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1)) #reshape non ha random state\n",
    "    X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train, random_state = 76)\n",
    "\n",
    "    n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "    print(\"TIMESTEPS: \", n_timesteps)\n",
    "    print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "    cnn = build_simple_cnn(n_timesteps, n_outputs, i)\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01) #Non ha random state\n",
    "\n",
    "    mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True) #Non ha random state\n",
    "\n",
    "\n",
    "    callbacks = [rlr, mc]\n",
    "\n",
    "    batch_size = 16\n",
    "    mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "    history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history #.fit non ha random state\n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "    print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una volta trovato il valore di i (seed) che da buoni risultati, \n",
    "#rilancia il modello 2 o 3 volte con quel valore per vedere se i risultati cambiano. \n",
    "# Se cambiano vuol dire che c'e' un altro random state da qualche parte e lo devi scovare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_450 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_478 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_450 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_511 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_451 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_479 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_451 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_512 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_226 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 414s 16s/step - loss: 0.7957 - acc: 0.3462 - val_loss: 2.5918 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6989 - acc: 0.5000 - val_loss: 1.7586 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6880 - acc: 0.7308 - val_loss: 1.8554 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 0.6644 - acc: 0.6923 - val_loss: 1.5460 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6496 - acc: 0.7308 - val_loss: 1.0999 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 18ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_452 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_480 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_452 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_513 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_453 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_481 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_453 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_514 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_227 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 400s 15s/step - loss: 0.7069 - acc: 0.6154 - val_loss: 0.7291 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6897 - acc: 0.6538 - val_loss: 0.6777 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 0.6849 - acc: 0.6538 - val_loss: 0.7642 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.6697 - acc: 0.6923 - val_loss: 0.7728 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6568 - acc: 0.7308 - val_loss: 0.7496 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_454 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_482 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_454 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_515 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_455 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_483 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_455 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_516 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_228 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 416s 16s/step - loss: 0.7286 - acc: 0.4231 - val_loss: 0.6868 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 0.6906 - acc: 0.6923 - val_loss: 0.7829 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6717 - acc: 0.7308 - val_loss: 0.8299 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6668 - acc: 0.7308 - val_loss: 0.7320 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6494 - acc: 0.6538 - val_loss: 0.7164 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_456 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_484 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_456 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_517 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_457 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_485 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_457 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_518 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_229 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 399s 15s/step - loss: 0.6997 - acc: 0.6923 - val_loss: 1.0984 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6736 - acc: 0.7308 - val_loss: 0.7359 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6604 - acc: 0.7308 - val_loss: 0.6619 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6433 - acc: 0.7308 - val_loss: 0.6449 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 0.6219 - acc: 0.7308 - val_loss: 0.6627 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_458 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_486 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_458 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_519 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_459 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_487 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_459 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_520 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_230 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 403s 16s/step - loss: 0.6898 - acc: 0.6923 - val_loss: 0.8593 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.6855 - acc: 0.7308 - val_loss: 0.7173 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.6528 - acc: 0.7308 - val_loss: 0.6738 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.6694 - acc: 0.7308 - val_loss: 0.6734 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6653 - acc: 0.7308 - val_loss: 0.7073 - val_acc: 0.2857\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.16666667 0.44444444]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        11\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.64      0.55      0.31        15\n",
      "weighted avg       0.81      0.33      0.24        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_460 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_488 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_460 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_521 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_461 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_489 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_461 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_522 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_231 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 417s 16s/step - loss: 0.7312 - acc: 0.5769 - val_loss: 1.0604 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6937 - acc: 0.7308 - val_loss: 0.7210 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6826 - acc: 0.6923 - val_loss: 0.6668 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.6676 - acc: 0.7308 - val_loss: 0.6532 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6387 - acc: 0.7308 - val_loss: 0.6132 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_462 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_490 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_462 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_523 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_463 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_491 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_463 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_524 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_232 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 412s 16s/step - loss: 0.7520 - acc: 0.3462 - val_loss: 1.5775 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.7306 - acc: 0.4231 - val_loss: 1.1937 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 0.7170 - acc: 0.3846 - val_loss: 0.6668 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6959 - acc: 0.5385 - val_loss: 0.6633 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6990 - acc: 0.7308 - val_loss: 0.8426 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_464 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_492 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_464 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_525 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_465 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_493 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_465 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_526 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_233 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 429s 17s/step - loss: 0.6842 - acc: 0.5769 - val_loss: 0.7046 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6701 - acc: 0.6923 - val_loss: 0.7037 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6301 - acc: 0.7308 - val_loss: 0.7093 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.5880 - acc: 0.6923 - val_loss: 0.7085 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.5961 - acc: 0.6538 - val_loss: 0.7029 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_466 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_494 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_466 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_527 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_467 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_495 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_467 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_528 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_234 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 420s 16s/step - loss: 0.7881 - acc: 0.6154 - val_loss: 0.6738 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 0.7272 - acc: 0.5385 - val_loss: 0.9099 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.7060 - acc: 0.6923 - val_loss: 0.8840 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6764 - acc: 0.7308 - val_loss: 0.6694 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6635 - acc: 0.6538 - val_loss: 0.6541 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_468 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_496 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_468 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_529 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_469 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_497 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_469 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_530 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_235 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 421s 16s/step - loss: 0.7135 - acc: 0.5000 - val_loss: 0.6808 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.6931 - acc: 0.6154 - val_loss: 0.7497 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6727 - acc: 0.7308 - val_loss: 0.7592 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6690 - acc: 0.7308 - val_loss: 0.6748 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6424 - acc: 0.7308 - val_loss: 0.6750 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "15/15 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs, i):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = i)) #EUREKA!!!!\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D()) #non ha random state\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid')) #Dense non ha random state\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #.compile non ha random state\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "for i in [14, 14, 14, 14, 14, 14, 14, 14, 14, 14]:\n",
    "    print('============================================', i, '=============================================================')\n",
    "    X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1)) #reshape non ha random state\n",
    "    X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train, random_state = 76)\n",
    "\n",
    "    n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "    print(\"TIMESTEPS: \", n_timesteps)\n",
    "    print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "    cnn = build_simple_cnn(n_timesteps, n_outputs, i)\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01) #Non ha random state\n",
    "\n",
    "    mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True) #Non ha random state\n",
    "\n",
    "\n",
    "    callbacks = [rlr, mc]\n",
    "\n",
    "    batch_size = 16\n",
    "    mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "    history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history #.fit non ha random state\n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "    print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 0 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_470 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_498 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_470 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_531 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_471 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_499 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_471 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_532 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_236 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 436s 17s/step - loss: 0.8359 - acc: 0.6154 - val_loss: 3.6002 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.7452 - acc: 0.6923 - val_loss: 0.7058 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6700 - acc: 0.7692 - val_loss: 0.9775 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6676 - acc: 0.7308 - val_loss: 1.1019 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6627 - acc: 0.6923 - val_loss: 0.8187 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 1 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_472 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_500 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_472 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_533 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_473 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_501 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_473 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_534 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_237 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 433s 17s/step - loss: 0.6987 - acc: 0.5385 - val_loss: 0.7948 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6839 - acc: 0.7308 - val_loss: 0.6331 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6727 - acc: 0.7308 - val_loss: 0.6518 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6697 - acc: 0.7308 - val_loss: 0.6410 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 0.6648 - acc: 0.7308 - val_loss: 0.6753 - val_acc: 0.7143\n",
      "Accuracy 0.6666666666666666\n",
      "F1-score [0.8 0. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.36      0.45      0.40        15\n",
      "weighted avg       0.52      0.67      0.59        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 2 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_474 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_502 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_474 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_535 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_475 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_503 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_475 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_536 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_238 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 437s 17s/step - loss: 0.6971 - acc: 0.5769 - val_loss: 0.7211 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6616 - acc: 0.5385 - val_loss: 0.7143 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6223 - acc: 0.7692 - val_loss: 0.7066 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6229 - acc: 0.6154 - val_loss: 0.7174 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.5515 - acc: 0.6538 - val_loss: 0.7175 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 3 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_476 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_504 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_476 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_537 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_477 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_505 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_477 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_538 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_239 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 437s 17s/step - loss: 0.7084 - acc: 0.6154 - val_loss: 1.0434 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6866 - acc: 0.6923 - val_loss: 0.7244 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6697 - acc: 0.7308 - val_loss: 0.6628 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6562 - acc: 0.7308 - val_loss: 0.6728 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6330 - acc: 0.7308 - val_loss: 0.6748 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 4 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_478 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_506 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_478 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_539 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_479 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_507 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_479 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_540 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_240 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 454s 17s/step - loss: 0.7525 - acc: 0.6154 - val_loss: 0.6362 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.7095 - acc: 0.6154 - val_loss: 0.7846 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6698 - acc: 0.7308 - val_loss: 0.9464 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6637 - acc: 0.6923 - val_loss: 0.8951 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6475 - acc: 0.7308 - val_loss: 0.6565 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 5 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_480 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_508 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_480 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_541 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_481 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_509 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_481 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_542 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_241 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 442s 17s/step - loss: 0.6879 - acc: 0.6538 - val_loss: 0.6503 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6984 - acc: 0.7308 - val_loss: 0.6383 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 0.6919 - acc: 0.7308 - val_loss: 0.6447 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.6732 - acc: 0.7308 - val_loss: 0.6601 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 0.6352 - acc: 0.7308 - val_loss: 0.7677 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 6 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_482 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_510 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_482 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_543 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_483 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_511 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_483 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_544 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_242 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 442s 17s/step - loss: 0.6927 - acc: 0.6923 - val_loss: 0.6375 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6657 - acc: 0.6923 - val_loss: 0.6691 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.6546 - acc: 0.6923 - val_loss: 0.6322 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.6068 - acc: 0.7308 - val_loss: 0.6320 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 133ms/step - loss: 0.6197 - acc: 0.7308 - val_loss: 0.6321 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 7 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_484 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_512 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_484 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_545 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_485 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_513 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_485 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_546 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_243 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 446s 17s/step - loss: 0.7063 - acc: 0.6154 - val_loss: 0.6782 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.7090 - acc: 0.4231 - val_loss: 0.6529 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.7000 - acc: 0.5000 - val_loss: 0.6311 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6586 - acc: 0.7308 - val_loss: 0.6414 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 0.6343 - acc: 0.7308 - val_loss: 0.6471 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 8 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_486 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_514 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_486 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_547 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_487 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_515 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_487 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_548 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_244 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 453s 17s/step - loss: 0.6819 - acc: 0.6923 - val_loss: 0.6311 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6828 - acc: 0.7308 - val_loss: 0.8336 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.6648 - acc: 0.7308 - val_loss: 0.6332 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 0.6421 - acc: 0.7308 - val_loss: 0.6897 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 0.6545 - acc: 0.7308 - val_loss: 0.6390 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 9 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_488 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_516 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_488 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_549 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_489 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_517 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_489 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_550 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_245 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 452s 17s/step - loss: 0.6965 - acc: 0.5385 - val_loss: 0.6863 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6915 - acc: 0.6154 - val_loss: 0.6761 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.6613 - acc: 0.6538 - val_loss: 0.6234 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6260 - acc: 0.7308 - val_loss: 0.7527 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.6131 - acc: 0.7308 - val_loss: 0.8376 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 10 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_490 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_518 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_490 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_551 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_491 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_519 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_491 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_552 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_246 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 459s 18s/step - loss: 0.7258 - acc: 0.4231 - val_loss: 0.6186 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.6965 - acc: 0.6538 - val_loss: 0.9989 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6955 - acc: 0.6923 - val_loss: 0.7510 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6649 - acc: 0.6154 - val_loss: 0.8381 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 0.6751 - acc: 0.6923 - val_loss: 0.7198 - val_acc: 0.2857\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.5 0. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.45      0.50        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.28      0.23      0.25        15\n",
      "weighted avg       0.41      0.33      0.37        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 1 0 1 0 0 0 1 1 1 1 0 0]\n",
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 11 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_492 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_520 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_492 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_553 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_493 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_521 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_493 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_554 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_247 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 459s 18s/step - loss: 0.6948 - acc: 0.6538 - val_loss: 0.8169 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6616 - acc: 0.7692 - val_loss: 0.8365 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6227 - acc: 0.6923 - val_loss: 0.7298 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.6397 - acc: 0.6154 - val_loss: 0.7239 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.5135 - acc: 0.7692 - val_loss: 0.7149 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 26ms/step\n",
      "============================================ 12 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_494 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_522 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_494 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_555 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_495 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_523 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_495 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_556 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_248 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 475s 18s/step - loss: 0.6967 - acc: 0.5000 - val_loss: 0.7355 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 0.6507 - acc: 0.6923 - val_loss: 1.4468 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.7001 - acc: 0.7308 - val_loss: 0.6753 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.6439 - acc: 0.7308 - val_loss: 0.6767 - val_acc: 0.8571\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6219 - acc: 0.7308 - val_loss: 0.7324 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 13 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_496 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_524 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_496 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_557 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_497 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_525 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_497 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_558 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_249 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 462s 18s/step - loss: 0.7061 - acc: 0.5769 - val_loss: 1.2447 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.6877 - acc: 0.7308 - val_loss: 1.1190 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.6914 - acc: 0.6538 - val_loss: 1.0688 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 135ms/step - loss: 0.6803 - acc: 0.7308 - val_loss: 0.6721 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 133ms/step - loss: 0.6638 - acc: 0.6923 - val_loss: 0.7394 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 14 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_498 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_526 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_498 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_559 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_499 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_527 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_499 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_560 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_250 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 477s 18s/step - loss: 0.7066 - acc: 0.3462 - val_loss: 0.6501 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6870 - acc: 0.6923 - val_loss: 0.6401 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6775 - acc: 0.6923 - val_loss: 0.6093 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6760 - acc: 0.7308 - val_loss: 0.6289 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 0.6342 - acc: 0.7308 - val_loss: 0.6429 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 15 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_500 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_528 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_500 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_561 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_501 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_529 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_501 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_562 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_251 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 473s 18s/step - loss: 0.7090 - acc: 0.5769 - val_loss: 0.6882 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6905 - acc: 0.6154 - val_loss: 0.6856 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.6657 - acc: 0.5385 - val_loss: 0.6740 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6421 - acc: 0.6538 - val_loss: 0.6715 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6110 - acc: 0.5769 - val_loss: 0.6676 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 16 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_502 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_530 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_502 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_563 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_503 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_531 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_503 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_564 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_252 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 486s 19s/step - loss: 0.7144 - acc: 0.6538 - val_loss: 0.6275 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.7044 - acc: 0.5385 - val_loss: 0.6276 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.6652 - acc: 0.7308 - val_loss: 0.6271 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.6499 - acc: 0.7308 - val_loss: 0.6406 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6245 - acc: 0.7308 - val_loss: 0.6667 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 17 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_504 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_532 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_504 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_565 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_505 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_533 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_505 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_566 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_253 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 484s 19s/step - loss: 0.6680 - acc: 0.7308 - val_loss: 1.9834 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.6615 - acc: 0.7308 - val_loss: 1.5019 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6421 - acc: 0.7308 - val_loss: 0.8459 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6253 - acc: 0.7308 - val_loss: 0.8050 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.5774 - acc: 0.7308 - val_loss: 0.6795 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 18 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_506 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_534 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_506 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_567 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_507 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_535 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_507 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_568 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_254 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 486s 19s/step - loss: 0.7001 - acc: 0.7308 - val_loss: 0.7661 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6808 - acc: 0.7308 - val_loss: 0.7923 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.6854 - acc: 0.7308 - val_loss: 0.8542 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 126ms/step - loss: 0.6522 - acc: 0.7308 - val_loss: 0.7754 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.6326 - acc: 0.7308 - val_loss: 0.7247 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 19 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_508 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_536 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_508 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_569 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_509 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_537 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_509 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_570 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_255 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 514s 20s/step - loss: 0.6950 - acc: 0.6154 - val_loss: 2.1668 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6732 - acc: 0.6923 - val_loss: 1.0239 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.6621 - acc: 0.7308 - val_loss: 1.2555 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.6495 - acc: 0.7308 - val_loss: 1.0337 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 135ms/step - loss: 0.6202 - acc: 0.7308 - val_loss: 0.7710 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 20 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_510 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_538 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_510 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_571 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_511 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_539 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_511 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_572 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_256 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 499s 19s/step - loss: 0.6991 - acc: 0.6538 - val_loss: 0.7470 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6589 - acc: 0.7308 - val_loss: 0.6648 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6166 - acc: 0.4615 - val_loss: 0.6594 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.5735 - acc: 0.5769 - val_loss: 0.6873 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.5946 - acc: 0.6154 - val_loss: 0.6551 - val_acc: 0.7143\n",
      "Accuracy 0.8666666666666667\n",
      "F1-score [0.91666667 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.92      0.75      0.79        15\n",
      "weighted avg       0.89      0.87      0.85        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 21 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_512 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_540 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_512 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_573 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_513 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_541 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_513 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_574 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_257 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 491s 19s/step - loss: 0.6892 - acc: 0.6538 - val_loss: 0.6118 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.6739 - acc: 0.7308 - val_loss: 0.7008 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.6639 - acc: 0.7308 - val_loss: 0.6459 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6394 - acc: 0.7308 - val_loss: 0.6725 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 0.6278 - acc: 0.7308 - val_loss: 0.6793 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 22 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_514 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_542 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_514 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_575 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_515 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_543 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_515 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_576 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_258 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 510s 20s/step - loss: 0.6861 - acc: 0.6923 - val_loss: 1.1114 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.6630 - acc: 0.7308 - val_loss: 0.6893 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6343 - acc: 0.7308 - val_loss: 0.7393 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.6418 - acc: 0.7308 - val_loss: 0.7290 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 131ms/step - loss: 0.6426 - acc: 0.7308 - val_loss: 0.6873 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 23 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_516 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_544 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_516 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_577 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_517 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_545 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_517 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_578 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_259 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 496s 19s/step - loss: 0.7007 - acc: 0.6154 - val_loss: 0.7440 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.6669 - acc: 0.8846 - val_loss: 0.7439 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6596 - acc: 0.7308 - val_loss: 0.7075 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6448 - acc: 0.7308 - val_loss: 0.6577 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6194 - acc: 0.7308 - val_loss: 0.7123 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 25ms/step\n",
      "============================================ 24 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_518 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_546 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_518 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_579 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_519 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_547 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_519 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_580 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_260 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 524s 20s/step - loss: 0.7092 - acc: 0.5385 - val_loss: 1.1335 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.6831 - acc: 0.6923 - val_loss: 1.1964 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.6769 - acc: 0.7308 - val_loss: 1.0613 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6840 - acc: 0.7308 - val_loss: 1.1408 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.6916 - acc: 0.6923 - val_loss: 0.6867 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 25 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_520 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_548 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_520 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_581 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_521 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_549 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_521 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_582 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_261 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 551s 21s/step - loss: 0.7212 - acc: 0.5769 - val_loss: 0.6777 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6897 - acc: 0.6923 - val_loss: 0.6640 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6709 - acc: 0.7308 - val_loss: 0.6596 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6598 - acc: 0.7308 - val_loss: 0.6411 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.6418 - acc: 0.7308 - val_loss: 0.6135 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 26 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_522 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_550 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_522 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_583 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_523 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_551 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_523 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_584 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_262 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 526s 20s/step - loss: 0.6862 - acc: 0.6538 - val_loss: 0.6815 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.6721 - acc: 0.6923 - val_loss: 0.9279 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 3s 128ms/step - loss: 0.6474 - acc: 0.6154 - val_loss: 0.7619 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6088 - acc: 0.6923 - val_loss: 0.6684 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 133ms/step - loss: 0.5646 - acc: 0.7308 - val_loss: 0.6981 - val_acc: 0.4286\n",
      "Accuracy 0.5333333333333333\n",
      "F1-score [0.53333333 0.53333333]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53        11\n",
      "           1       0.36      1.00      0.53         4\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.68      0.68      0.53        15\n",
      "weighted avg       0.83      0.53      0.53        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 1 0 0 1 1 1]\n",
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 27 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_524 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_552 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_524 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_585 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_525 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_553 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_525 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_586 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_263 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 512s 20s/step - loss: 0.7402 - acc: 0.6154 - val_loss: 1.6682 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6892 - acc: 0.6538 - val_loss: 0.6789 - val_acc: 0.8571\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.6686 - acc: 0.6538 - val_loss: 0.6130 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6300 - acc: 0.6923 - val_loss: 0.9648 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.5876 - acc: 0.7308 - val_loss: 1.0286 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 28 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_526 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_554 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_526 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_587 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_527 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_555 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_527 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_588 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_264 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 528s 20s/step - loss: 0.6818 - acc: 0.5769 - val_loss: 0.6897 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.6708 - acc: 0.6538 - val_loss: 0.6763 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.6196 - acc: 0.7308 - val_loss: 0.6274 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.5762 - acc: 0.7308 - val_loss: 0.6442 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.5619 - acc: 0.6923 - val_loss: 0.6610 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 29 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_528 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_556 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_528 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_589 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_529 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_557 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_529 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_590 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_265 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 513s 20s/step - loss: 0.7379 - acc: 0.5769 - val_loss: 0.7255 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 0.6970 - acc: 0.5385 - val_loss: 0.6653 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6682 - acc: 0.6923 - val_loss: 0.6759 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 0.6566 - acc: 0.7308 - val_loss: 0.7532 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.6737 - acc: 0.7308 - val_loss: 0.6978 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 30 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_530 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_558 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_530 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_591 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_531 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_559 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_531 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_592 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_266 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 531s 20s/step - loss: 0.6848 - acc: 0.6923 - val_loss: 1.5945 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.7279 - acc: 0.7308 - val_loss: 0.7919 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.7026 - acc: 0.6538 - val_loss: 1.5343 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.6851 - acc: 0.6154 - val_loss: 0.7574 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6514 - acc: 0.6923 - val_loss: 0.7028 - val_acc: 0.4286\n",
      "Accuracy 0.6666666666666666\n",
      "F1-score [0.70588235 0.61538462]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71        11\n",
      "           1       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.72      0.77      0.66        15\n",
      "weighted avg       0.85      0.67      0.68        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 1 0 1 1 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 31 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_532 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_560 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_532 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_593 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_533 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_561 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_533 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_594 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_267 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 526s 20s/step - loss: 0.6856 - acc: 0.7308 - val_loss: 0.6734 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.6712 - acc: 0.7308 - val_loss: 0.6037 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.6287 - acc: 0.7308 - val_loss: 0.6301 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6327 - acc: 0.7308 - val_loss: 0.6756 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 136ms/step - loss: 0.5854 - acc: 0.6923 - val_loss: 0.6768 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 32 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_534 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_562 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_534 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_595 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_535 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_563 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_535 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_596 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_268 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 547s 21s/step - loss: 0.7028 - acc: 0.6154 - val_loss: 0.6741 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.6890 - acc: 0.6923 - val_loss: 0.6383 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6702 - acc: 0.6923 - val_loss: 0.6131 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6569 - acc: 0.7308 - val_loss: 0.6449 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6182 - acc: 0.7308 - val_loss: 0.6138 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 33 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_536 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_564 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_536 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_597 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_537 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_565 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_537 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_598 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_269 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 539s 21s/step - loss: 0.7056 - acc: 0.5000 - val_loss: 1.0592 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6750 - acc: 0.7692 - val_loss: 0.7452 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.6582 - acc: 0.6538 - val_loss: 0.6907 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.6204 - acc: 0.7308 - val_loss: 0.6762 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 157ms/step - loss: 0.5946 - acc: 0.7308 - val_loss: 0.6591 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 27ms/step\n",
      "============================================ 34 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_538 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_566 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_538 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_599 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_539 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_567 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_539 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_600 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_270 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 560s 22s/step - loss: 0.6955 - acc: 0.4615 - val_loss: 0.6476 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 3s 133ms/step - loss: 0.6923 - acc: 0.6923 - val_loss: 0.6915 - val_acc: 0.5714\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.6691 - acc: 0.6923 - val_loss: 0.6808 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 133ms/step - loss: 0.6367 - acc: 0.6923 - val_loss: 0.6809 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.6352 - acc: 0.7308 - val_loss: 0.7137 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 27ms/step\n",
      "============================================ 35 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_540 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_568 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_540 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_601 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_541 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_569 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_541 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_602 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_271 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 566s 22s/step - loss: 0.7278 - acc: 0.6538 - val_loss: 0.7278 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.7051 - acc: 0.6538 - val_loss: 0.7070 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.6680 - acc: 0.7308 - val_loss: 0.6942 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6635 - acc: 0.7692 - val_loss: 0.6481 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.6362 - acc: 0.7308 - val_loss: 0.6369 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 36 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_542 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_570 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_542 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_603 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_543 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_571 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_543 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_604 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_272 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 562s 22s/step - loss: 0.6997 - acc: 0.6154 - val_loss: 0.8707 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.6466 - acc: 0.6923 - val_loss: 0.6540 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6499 - acc: 0.7308 - val_loss: 0.6579 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6116 - acc: 0.7308 - val_loss: 0.6797 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.5982 - acc: 0.7308 - val_loss: 0.7109 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 37 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_544 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_572 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_544 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_605 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_545 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_573 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_545 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_606 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_273 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 556s 21s/step - loss: 0.6927 - acc: 0.6154 - val_loss: 0.7052 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.6764 - acc: 0.7308 - val_loss: 0.7101 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.6494 - acc: 0.6923 - val_loss: 0.7429 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6274 - acc: 0.5769 - val_loss: 0.7229 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.5997 - acc: 0.6923 - val_loss: 0.7019 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 38 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_546 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_574 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_546 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_607 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_547 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_575 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_547 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_608 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_274 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 604s 23s/step - loss: 0.7202 - acc: 0.6538 - val_loss: 5.0105 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6949 - acc: 0.5769 - val_loss: 0.8195 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6814 - acc: 0.7308 - val_loss: 1.0320 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6605 - acc: 0.7308 - val_loss: 1.1941 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 132ms/step - loss: 0.6399 - acc: 0.7308 - val_loss: 0.9557 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 27ms/step\n",
      "============================================ 39 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_548 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_576 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_548 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_609 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_549 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_577 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_549 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_610 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_275 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 555s 21s/step - loss: 0.7062 - acc: 0.6538 - val_loss: 1.2499 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6698 - acc: 0.7308 - val_loss: 0.6596 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.6761 - acc: 0.7308 - val_loss: 0.6567 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6395 - acc: 0.7308 - val_loss: 0.5839 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 142ms/step - loss: 0.6306 - acc: 0.7308 - val_loss: 0.7422 - val_acc: 0.2857\n",
      "Accuracy 0.3333333333333333\n",
      "F1-score [0.16666667 0.44444444]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        11\n",
      "           1       0.29      1.00      0.44         4\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.64      0.55      0.31        15\n",
      "weighted avg       0.81      0.33      0.24        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 40 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_550 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_578 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_550 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_611 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_551 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_579 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_551 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_612 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_276 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 581s 22s/step - loss: 0.7034 - acc: 0.7308 - val_loss: 0.7371 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.6876 - acc: 0.7308 - val_loss: 0.7348 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.6698 - acc: 0.7308 - val_loss: 0.7280 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 141ms/step - loss: 0.6678 - acc: 0.7308 - val_loss: 0.7305 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.6652 - acc: 0.7308 - val_loss: 0.8055 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 41 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_552 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_580 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_552 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_613 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_553 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_581 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_553 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_614 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_277 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 569s 22s/step - loss: 0.6906 - acc: 0.7308 - val_loss: 1.2604 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.6619 - acc: 0.6923 - val_loss: 0.7130 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.6330 - acc: 0.6538 - val_loss: 0.6938 - val_acc: 0.5714\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6326 - acc: 0.6154 - val_loss: 0.7252 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.5752 - acc: 0.6923 - val_loss: 0.6990 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step\n",
      "============================================ 42 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_554 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_582 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_554 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_615 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_555 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_583 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_555 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_616 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_278 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 579s 22s/step - loss: 0.6771 - acc: 0.7308 - val_loss: 1.9597 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6968 - acc: 0.7308 - val_loss: 0.6666 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.6576 - acc: 0.7308 - val_loss: 0.8164 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.6280 - acc: 0.6154 - val_loss: 0.8987 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.6219 - acc: 0.6154 - val_loss: 0.7765 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 43 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_556 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_584 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_556 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_617 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_557 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_585 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_557 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_618 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_279 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 573s 22s/step - loss: 0.7276 - acc: 0.6154 - val_loss: 2.0676 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 143ms/step - loss: 0.7090 - acc: 0.7308 - val_loss: 0.7787 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6822 - acc: 0.6923 - val_loss: 0.7762 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6657 - acc: 0.7308 - val_loss: 0.7021 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 150ms/step - loss: 0.6522 - acc: 0.7308 - val_loss: 0.6783 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.77777778 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        11\n",
      "           1       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.75      0.82      0.72        15\n",
      "weighted avg       0.87      0.73      0.75        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 21ms/step\n",
      "============================================ 44 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_558 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_586 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_558 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_619 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_559 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_587 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_559 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_620 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_280 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 589s 23s/step - loss: 0.7771 - acc: 0.4231 - val_loss: 1.6253 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.6907 - acc: 0.6923 - val_loss: 0.8076 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.6755 - acc: 0.6923 - val_loss: 1.1566 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.6483 - acc: 0.6923 - val_loss: 1.1692 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.6410 - acc: 0.6538 - val_loss: 0.9572 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 45 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_560 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_588 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_560 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_621 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_561 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_589 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_561 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_622 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_281 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 584s 22s/step - loss: 0.7132 - acc: 0.6154 - val_loss: 0.6798 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.6668 - acc: 0.7308 - val_loss: 0.6742 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.6425 - acc: 0.7308 - val_loss: 0.7344 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6291 - acc: 0.7308 - val_loss: 0.6851 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 138ms/step - loss: 0.6455 - acc: 0.6923 - val_loss: 0.6892 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 46 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_562 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_590 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_562 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_623 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_563 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_591 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_563 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_624 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_282 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 592s 23s/step - loss: 0.6947 - acc: 0.7308 - val_loss: 0.6930 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 0.6854 - acc: 0.7308 - val_loss: 0.7120 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.6149 - acc: 0.7308 - val_loss: 0.8376 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 140ms/step - loss: 0.5817 - acc: 0.7308 - val_loss: 0.8456 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 135ms/step - loss: 0.5547 - acc: 0.7308 - val_loss: 0.8131 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 47 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_564 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_592 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_564 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_625 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_565 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_593 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_565 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_626 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_283 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 588s 23s/step - loss: 0.6781 - acc: 0.7308 - val_loss: 1.7823 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.6552 - acc: 0.6923 - val_loss: 1.2264 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.6278 - acc: 0.6923 - val_loss: 0.7571 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.5785 - acc: 0.6923 - val_loss: 0.6985 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.5449 - acc: 0.6538 - val_loss: 0.7462 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_566 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_594 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_566 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_627 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_567 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_595 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_567 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_628 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_284 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 608s 23s/step - loss: 0.7197 - acc: 0.6538 - val_loss: 0.7619 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.6683 - acc: 0.7308 - val_loss: 0.7500 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.6229 - acc: 0.7308 - val_loss: 0.6706 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.6220 - acc: 0.7308 - val_loss: 0.6540 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.5519 - acc: 0.7308 - val_loss: 0.6604 - val_acc: 0.7143\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95652174 0.85714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.88      0.91        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 0s 24ms/step\n",
      "============================================ 49 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_568 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_596 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_568 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_629 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_569 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_597 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_569 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_630 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_285 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 943s 36s/step - loss: 0.7681 - acc: 0.3846 - val_loss: 2.0933 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.7105 - acc: 0.6154 - val_loss: 2.0641 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.6955 - acc: 0.6923 - val_loss: 1.7456 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 0.6705 - acc: 0.6923 - val_loss: 1.4653 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.6789 - acc: 0.7308 - val_loss: 1.4573 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 30ms/step\n",
      "============================================ 50 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_570 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_598 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_570 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_631 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_571 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_599 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_571 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_632 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_286 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 986s 38s/step - loss: 0.7120 - acc: 0.6538 - val_loss: 1.7519 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.7020 - acc: 0.6923 - val_loss: 1.8705 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.6690 - acc: 0.7308 - val_loss: 1.6389 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.6651 - acc: 0.6923 - val_loss: 1.3744 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 218ms/step - loss: 0.6632 - acc: 0.7308 - val_loss: 1.1456 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 29ms/step\n",
      "============================================ 51 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_572 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_600 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_572 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_633 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_573 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_601 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_573 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_634 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_287 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 982s 38s/step - loss: 0.7198 - acc: 0.4615 - val_loss: 1.4401 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 219ms/step - loss: 0.6726 - acc: 0.7692 - val_loss: 0.6781 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.6489 - acc: 0.7308 - val_loss: 0.6873 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.6121 - acc: 0.7308 - val_loss: 0.6757 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 208ms/step - loss: 0.5995 - acc: 0.7308 - val_loss: 0.6808 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 32ms/step\n",
      "============================================ 52 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_574 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_602 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_574 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_635 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_575 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_603 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_575 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_636 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_288 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 999s 38s/step - loss: 0.6968 - acc: 0.7692 - val_loss: 0.7233 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.6434 - acc: 0.8077 - val_loss: 0.8084 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.6301 - acc: 0.6538 - val_loss: 0.8108 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.6043 - acc: 0.6154 - val_loss: 0.6461 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.5846 - acc: 0.7308 - val_loss: 0.6989 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 30ms/step\n",
      "============================================ 53 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_576 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_604 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_576 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_637 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_577 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_605 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_577 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_638 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_289 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 999s 38s/step - loss: 0.6979 - acc: 0.6538 - val_loss: 1.7975 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.6923 - acc: 0.7308 - val_loss: 1.1399 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 0.6699 - acc: 0.7308 - val_loss: 0.7212 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.6608 - acc: 0.7308 - val_loss: 0.6935 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.6306 - acc: 0.7308 - val_loss: 0.6884 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 32ms/step\n",
      "============================================ 54 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_578 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_606 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_578 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_639 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_579 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_607 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_579 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_640 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_290 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 777s 30s/step - loss: 0.8531 - acc: 0.2692 - val_loss: 1.4867 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 144ms/step - loss: 0.6921 - acc: 0.6538 - val_loss: 1.9759 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.6854 - acc: 0.6538 - val_loss: 2.5073 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.6952 - acc: 0.7308 - val_loss: 1.8794 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.6667 - acc: 0.6923 - val_loss: 1.0439 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 25ms/step\n",
      "============================================ 55 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_580 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_608 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_580 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_641 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_581 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_609 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_581 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_642 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_291 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 641s 25s/step - loss: 0.6883 - acc: 0.7308 - val_loss: 0.9208 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.6482 - acc: 0.5769 - val_loss: 0.8661 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.6342 - acc: 0.7308 - val_loss: 0.8066 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.6033 - acc: 0.6154 - val_loss: 0.7812 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.5768 - acc: 0.6154 - val_loss: 0.7546 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 26ms/step\n",
      "============================================ 56 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_582 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_610 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_582 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_643 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_583 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_611 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_583 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_644 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_292 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 734s 28s/step - loss: 0.7128 - acc: 0.6923 - val_loss: 0.7491 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.6791 - acc: 0.6154 - val_loss: 0.7240 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 184ms/step - loss: 0.6609 - acc: 0.7308 - val_loss: 0.6285 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.6328 - acc: 0.7308 - val_loss: 0.5997 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.6345 - acc: 0.7308 - val_loss: 0.5977 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 28ms/step\n",
      "============================================ 57 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_584 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_612 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_584 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_645 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_585 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_613 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_585 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_646 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_293 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 784s 30s/step - loss: 0.7115 - acc: 0.6538 - val_loss: 1.4091 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 186ms/step - loss: 0.6924 - acc: 0.6154 - val_loss: 0.7601 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.6749 - acc: 0.7308 - val_loss: 0.6934 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.6616 - acc: 0.7308 - val_loss: 0.9865 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.6446 - acc: 0.7692 - val_loss: 0.9472 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 28ms/step\n",
      "============================================ 58 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_586 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_614 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_586 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_647 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_587 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_615 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_587 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_648 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_294 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 708s 27s/step - loss: 0.7229 - acc: 0.5385 - val_loss: 0.7308 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.7001 - acc: 0.5385 - val_loss: 0.7224 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.6698 - acc: 0.6923 - val_loss: 0.7308 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.6588 - acc: 0.6154 - val_loss: 0.7316 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.6382 - acc: 0.6538 - val_loss: 0.7150 - val_acc: 0.2857\n",
      "Accuracy 0.26666666666666666\n",
      "F1-score [0.         0.42105263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.27      1.00      0.42         4\n",
      "\n",
      "    accuracy                           0.27        15\n",
      "   macro avg       0.13      0.50      0.21        15\n",
      "weighted avg       0.07      0.27      0.11        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 29ms/step\n",
      "============================================ 59 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_588 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_616 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_588 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_649 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_589 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_617 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_589 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_650 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_295 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 676s 26s/step - loss: 0.7357 - acc: 0.5385 - val_loss: 2.4736 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.6783 - acc: 0.7308 - val_loss: 0.9413 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.6459 - acc: 0.7308 - val_loss: 0.9733 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.6395 - acc: 0.7308 - val_loss: 0.7753 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.6019 - acc: 0.6923 - val_loss: 0.7266 - val_acc: 0.2857\n",
      "Accuracy 0.4\n",
      "F1-score [0.30769231 0.47058824]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        11\n",
      "           1       0.31      1.00      0.47         4\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.65      0.59      0.39        15\n",
      "weighted avg       0.82      0.40      0.35        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 1 1 1 1 0 1 1 1 1 1 1 1]\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "============================================ 60 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_590 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_618 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_590 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_651 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_591 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_619 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_591 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_652 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_296 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 683s 26s/step - loss: 0.6968 - acc: 0.5769 - val_loss: 0.7565 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.6958 - acc: 0.7308 - val_loss: 0.7394 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.6664 - acc: 0.7308 - val_loss: 0.7107 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.6393 - acc: 0.7308 - val_loss: 0.7042 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.6315 - acc: 0.7308 - val_loss: 0.7437 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 27ms/step\n",
      "============================================ 61 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_592 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_620 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_592 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_653 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_593 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_621 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_593 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_654 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_297 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "24/26 [==========================>...] - ETA: 13s - loss: 0.7131 - acc: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-273-0b0ead2dfe5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n\u001b[1;32m---> 56\u001b[1;33m                           validation_data=(X_val_cnn, y_val_cnn)).history #.fit non ha random state\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1231\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1234\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   2554\u001b[0m         \"\"\"\n\u001b[0;32m   2555\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2556\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   2850\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2851\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2852\u001b[1;33m         \u001b[0mweight_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2853\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(ops)\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \"\"\"\n\u001b[0;32m   2196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2197\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2198\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\andre\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs, i):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1))) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = i)) #EUREKA!!!!\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = 66)) #EUREKA!!!!\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D()) #non ha random state\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid')) #Dense non ha random state\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #.compile non ha random state\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    print('============================================', i, '=============================================================')\n",
    "    X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1)) #reshape non ha random state\n",
    "    X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train, random_state = 76) #EUREKA!!!!\n",
    "\n",
    "    n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "    print(\"TIMESTEPS: \", n_timesteps)\n",
    "    print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "    cnn = build_simple_cnn(n_timesteps, n_outputs, i)\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01) #Non ha random state\n",
    "\n",
    "    mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True) #Non ha random state\n",
    "\n",
    "\n",
    "    callbacks = [rlr, mc]\n",
    "\n",
    "    batch_size = 16\n",
    "    mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "    history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history #.fit non ha random state\n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "    print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_604 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_632 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_604 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_665 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_605 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_633 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_605 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_666 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_303 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 719s 28s/step - loss: 0.7348 - acc: 0.6154 - val_loss: 1.1319 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.6828 - acc: 0.6923 - val_loss: 1.2912 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.6651 - acc: 0.7308 - val_loss: 1.1793 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.6477 - acc: 0.7308 - val_loss: 1.0301 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.6371 - acc: 0.7308 - val_loss: 0.8899 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 26ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_606 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_634 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_606 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_667 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_607 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_635 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_607 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_668 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_304 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 719s 28s/step - loss: 0.7022 - acc: 0.5385 - val_loss: 0.6590 - val_acc: 0.7143\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.6796 - acc: 0.7308 - val_loss: 0.6376 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6707 - acc: 0.6923 - val_loss: 0.6270 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.6479 - acc: 0.7308 - val_loss: 0.6316 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.6295 - acc: 0.7308 - val_loss: 0.6378 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 29ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_608 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_636 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_608 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_669 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_609 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_637 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_609 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_670 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_305 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 727s 28s/step - loss: 0.6746 - acc: 0.6923 - val_loss: 1.5053 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.6432 - acc: 0.7308 - val_loss: 0.9761 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.6100 - acc: 0.7308 - val_loss: 0.7859 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.5875 - acc: 0.7308 - val_loss: 0.7249 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.5650 - acc: 0.7308 - val_loss: 0.6592 - val_acc: 0.4286\n",
      "Accuracy 0.8\n",
      "F1-score [0.84210526 0.72727273]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84        11\n",
      "           1       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.79      0.86      0.78        15\n",
      "weighted avg       0.89      0.80      0.81        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 1 0 1 0 1 0 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 26ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_610 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_638 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_610 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_671 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_611 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_639 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_611 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_672 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_306 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 730s 28s/step - loss: 0.7228 - acc: 0.5769 - val_loss: 0.9051 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.6849 - acc: 0.6923 - val_loss: 1.0537 - val_acc: 0.2857\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.6733 - acc: 0.7308 - val_loss: 0.6976 - val_acc: 0.2857\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.6740 - acc: 0.7692 - val_loss: 0.8067 - val_acc: 0.2857\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.6586 - acc: 0.8077 - val_loss: 0.6867 - val_acc: 0.5714\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.77777778 0.66666667]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        11\n",
      "           1       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.75      0.82      0.72        15\n",
      "weighted avg       0.87      0.73      0.75        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 0 0 0 0 1 1]\n",
      "15/15 [==============================] - 0s 25ms/step\n",
      "============================================ 48 =============================================================\n",
      "TIMESTEPS:  360\n",
      "N. LABELS:  2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_612 (Conv1D)          (None, 353, 16)           144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_640 (Bat (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_612 (Activation)  (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_673 (Dropout)        (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_613 (Conv1D)          (None, 351, 64)           3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_641 (Bat (None, 351, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_613 (Activation)  (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_674 (Dropout)        (None, 351, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_307 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,730\n",
      "Trainable params: 3,570\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 737s 28s/step - loss: 0.6950 - acc: 0.6154 - val_loss: 0.6954 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.6835 - acc: 0.7308 - val_loss: 0.6901 - val_acc: 0.7143\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.6645 - acc: 0.7308 - val_loss: 0.6768 - val_acc: 0.7143\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.6481 - acc: 0.7308 - val_loss: 0.6708 - val_acc: 0.7143\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.6271 - acc: 0.7308 - val_loss: 0.6737 - val_acc: 0.7143\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "15/15 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs, i):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, 1))) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = i)) #EUREKA!!!!\n",
    "    \n",
    "#    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "#    model.add(BatchNormalization())\n",
    "#    model.add(Activation('relu'))\n",
    "    \n",
    "#    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) #Conv1D non ha random state\n",
    "    model.add(BatchNormalization()) #BatchNormalization non ha random state\n",
    "    model.add(Activation('relu')) #non ha random state\n",
    "    \n",
    "    model.add(Dropout(0.3, seed = 66)) #EUREKA!!!!\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D()) #non ha random state\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid')) #Dense non ha random state\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #.compile non ha random state\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "for i in [48, 48, 48, 48, 48]:\n",
    "    print('============================================', i, '=============================================================')\n",
    "    X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1)) #reshape non ha random state\n",
    "    X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train, random_state = 76) #EUREKA!!!!\n",
    "\n",
    "    n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "    print(\"TIMESTEPS: \", n_timesteps)\n",
    "    print(\"N. LABELS: \", n_outputs)\n",
    "\n",
    "    cnn = build_simple_cnn(n_timesteps, n_outputs, i)\n",
    "\n",
    "    cnn.summary()\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.01) #Non ha random state\n",
    "\n",
    "    mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True) #Non ha random state\n",
    "\n",
    "\n",
    "    callbacks = [rlr, mc]\n",
    "\n",
    "    batch_size = 16\n",
    "    mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))\n",
    "\n",
    "    history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=5, batch_size=mini_batch_size, shuffle = False, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history #.fit ha shuffle!!! \n",
    "\n",
    "    y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "    print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(y_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anche con shuffle = False dentro fit i risultati cambiano... non so piu' che pesci pigliare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 0.5425 - acc: 0.5769 - val_loss: 0.3373 - val_acc: 0.8571\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5101 - acc: 0.5385 - val_loss: 0.3398 - val_acc: 0.8571\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4547 - acc: 0.6154 - val_loss: 0.3392 - val_acc: 0.8571\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5497 - acc: 0.6538 - val_loss: 0.3473 - val_acc: 0.8571\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4645 - acc: 0.6154 - val_loss: 0.3663 - val_acc: 0.8571\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3891 - acc: 0.6923 - val_loss: 0.3567 - val_acc: 0.8571\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4596 - acc: 0.5769 - val_loss: 0.3633 - val_acc: 0.8571\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4355 - acc: 0.6538 - val_loss: 0.3689 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5148 - acc: 0.6923 - val_loss: 0.3529 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4595 - acc: 0.6154 - val_loss: 0.3537 - val_acc: 1.0000\n",
      "Accuracy 0.9333333333333333\n",
      "F1-score [0.95652174 0.85714286]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.96      0.88      0.91        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "15/15 [==============================] - 2s 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6752386689186096, 0.9333333373069763]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_lstm(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm = build_lstm(n_timesteps, n_outputs)\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "history_lstm = cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                       validation_data=(X_val_cnn, y_val_cnn)).history\n",
    "\n",
    "y_pred = np.argmax(lstm.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "lstm.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 26 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 3s 127ms/step - loss: 0.4294 - acc: 0.5769 - val_loss: 0.3816 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4972 - acc: 0.5769 - val_loss: 0.3707 - val_acc: 0.8571\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4470 - acc: 0.5769 - val_loss: 0.3601 - val_acc: 0.8571\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5031 - acc: 0.7692 - val_loss: 0.3478 - val_acc: 0.8571\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5821 - acc: 0.5769 - val_loss: 0.3306 - val_acc: 0.8571\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4770 - acc: 0.6154 - val_loss: 0.3480 - val_acc: 0.8571\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6009 - acc: 0.6154 - val_loss: 0.3734 - val_acc: 0.8571\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5486 - acc: 0.5385 - val_loss: 0.4102 - val_acc: 0.8571 \n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6070 - acc: 0.6154 - val_loss: 0.4408 - val_acc: 0.8571\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5398 - acc: 0.5769 - val_loss: 0.4724 - val_acc: 1.0000\n",
      "Accuracy 0.7333333333333333\n",
      "F1-score [0.84615385 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.37      0.50      0.42        15\n",
      "weighted avg       0.54      0.73      0.62        15\n",
      "\n",
      "[0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "15/15 [==============================] - 2s 109ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931471228599548, 0.7333333492279053]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_lstm(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm = build_lstm(n_timesteps, n_outputs)\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "history_lstm = cnn.fit(X_train_cnn, y_train_cnn, epochs=10, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                       validation_data=(X_val_cnn, y_val_cnn)).history\n",
    "\n",
    "y_pred = np.argmax(lstm.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "\n",
    "lstm.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x0000016C218F9348>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_basic_motions\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6, 100)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_basic_motions(return_X_y=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'Standing', b'Standing', b'Standing', b'Standing', b'Standing',\n",
       "       b'Standing', b'Standing', b'Standing', b'Standing', b'Standing',\n",
       "       b'Running', b'Running', b'Running', b'Running', b'Running',\n",
       "       b'Running', b'Running', b'Running', b'Running', b'Running',\n",
       "       b'Walking', b'Walking', b'Walking', b'Walking', b'Walking',\n",
       "       b'Walking', b'Walking', b'Walking', b'Walking', b'Walking',\n",
       "       b'Badminton', b'Badminton', b'Badminton', b'Badminton',\n",
       "       b'Badminton', b'Badminton', b'Badminton', b'Badminton',\n",
       "       b'Badminton', b'Badminton'], dtype='|S12')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(40, 100, 6)\n",
    "X_test = X_test.reshape(40, 100, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  100\n",
      "N. LABELS:  4\n",
      "N. FEATURES:  6\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2] \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "print(\"N. FEATURES: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm2(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(4, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "lstm2 = build_lstm2(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100, 4)            176       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 4)            144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100, 4)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 100,708\n",
      "Trainable params: 99,404\n",
      "Non-trainable params: 1,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 15s 480ms/step - loss: 1.6419 - acc: 0.1875 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 1.6477 - acc: 0.2188 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.4625 - acc: 0.2812 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.4005 - acc: 0.3750 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.4418 - acc: 0.3125 - val_loss: 1.3865 - val_acc: 0.2500\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.5115 - acc: 0.2188 - val_loss: 1.3866 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.5018 - acc: 0.2812 - val_loss: 1.3867 - val_acc: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3421 - acc: 0.4062 - val_loss: 1.3868 - val_acc: 0.2500\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.3774 - acc: 0.3438 - val_loss: 1.3869 - val_acc: 0.2500\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.3933 - acc: 0.4062 - val_loss: 1.3871 - val_acc: 0.2500\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.4066 - acc: 0.1875 - val_loss: 1.3872 - val_acc: 0.2500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.3436 - acc: 0.3438 - val_loss: 1.3874 - val_acc: 0.2500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.3655 - acc: 0.2500 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 1.3013 - acc: 0.3750 - val_loss: 1.3876 - val_acc: 0.2500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 1.3173 - acc: 0.2812 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.1984 - acc: 0.4688 - val_loss: 1.3876 - val_acc: 0.2500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.3844 - acc: 0.3750 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.3099 - acc: 0.3125 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.4372 - acc: 0.1875 - val_loss: 1.3874 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.4219 - acc: 0.3438 - val_loss: 1.3873 - val_acc: 0.2500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.2272 - acc: 0.3438 - val_loss: 1.3874 - val_acc: 0.2500\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.3261 - acc: 0.4062 - val_loss: 1.3876 - val_acc: 0.2500\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.5174 - acc: 0.2812 - val_loss: 1.3877 - val_acc: 0.2500\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.5157 - acc: 0.2500 - val_loss: 1.3878 - val_acc: 0.2500\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.3322 - acc: 0.4688 - val_loss: 1.3877 - val_acc: 0.2500\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.2191 - acc: 0.3125 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.2809 - acc: 0.4375 - val_loss: 1.3877 - val_acc: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2905 - acc: 0.3125 - val_loss: 1.3878 - val_acc: 0.2500\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1842 - acc: 0.4375 - val_loss: 1.3880 - val_acc: 0.2500\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3699 - acc: 0.4062 - val_loss: 1.3878 - val_acc: 0.2500\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.4029 - acc: 0.3125 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.4037 - acc: 0.3125 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2489 - acc: 0.2812 - val_loss: 1.3880 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.1595 - acc: 0.4062 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.3658 - acc: 0.2812 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.3240 - acc: 0.3438 - val_loss: 1.3879 - val_acc: 0.2500\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.2056 - acc: 0.3750 - val_loss: 1.3881 - val_acc: 0.2500\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.1919 - acc: 0.5000 - val_loss: 1.3886 - val_acc: 0.2500\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.2474 - acc: 0.4062 - val_loss: 1.3888 - val_acc: 0.2500\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.3928 - acc: 0.3438 - val_loss: 1.3893 - val_acc: 0.2500\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.3296 - acc: 0.3125 - val_loss: 1.3896 - val_acc: 0.2500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3041 - acc: 0.4375 - val_loss: 1.3899 - val_acc: 0.2500\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.3872 - acc: 0.2500 - val_loss: 1.3894 - val_acc: 0.2500\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 1.2648 - acc: 0.4375 - val_loss: 1.3900 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.1787 - acc: 0.4375 - val_loss: 1.3902 - val_acc: 0.2500\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2320 - acc: 0.5000 - val_loss: 1.3898 - val_acc: 0.2500\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2849 - acc: 0.3125 - val_loss: 1.3909 - val_acc: 0.2500\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 1.1853 - acc: 0.4062 - val_loss: 1.3915 - val_acc: 0.2500\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.1325 - acc: 0.6250 - val_loss: 1.3930 - val_acc: 0.2500\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.2601 - acc: 0.4688 - val_loss: 1.3927 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history_lstm2 = lstm2.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.25\n",
      "F1-score [0.  0.  0.  0.4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.25      1.00      0.40        10\n",
      "\n",
      "    accuracy                           0.25        40\n",
      "   macro avg       0.06      0.25      0.10        40\n",
      "weighted avg       0.06      0.25      0.10        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm2.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 6)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 6, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cnn2 = X_train_cnn.reshape(X_train_cnn.shape[0], X_train_cnn.shape[1], X_train_cnn.shape[2], 1)\n",
    "X_val_cnn2 = X_val_cnn.reshape(X_val_cnn.shape[0], X_val_cnn.shape[1], X_val_cnn.shape[2], 1)\n",
    "X_test_cnn2 = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "X_train_cnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn2(n_timesteps, n_features, n_outputs):\n",
    "    input_shape = (n_timesteps, n_features, 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    ks1_first = 3\n",
    "    ks1_second = 3\n",
    "    \n",
    "    ks2_first = 4\n",
    "    ks2_second = 4\n",
    "    \n",
    "    model.add(Conv2D(filters=(3), \n",
    "                     kernel_size=(ks1_first, ks1_second),\n",
    "                     input_shape=input_shape, \n",
    "                     padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.02))\n",
    "    \n",
    "    for _ in range(2):\n",
    "        model.add(Conv2D(filters=(4), \n",
    "                     kernel_size= (ks2_first, ks2_second), \n",
    "                         padding='same',\n",
    "                     kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))  \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(Dense(64 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "    for _ in range(3):\n",
    "        model.add(Dense(128 , kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.3))\n",
    "  \n",
    "    model.add(Dense(1024 , kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\andre\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1259: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "cnn2 = build_cnn2(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 6, 3)         30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100, 6, 3)         12        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 100, 6, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100, 6, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 6, 4)         196       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 100, 6, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 6, 4)         260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 100, 6, 4)         16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100, 6, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                153664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 4100      \n",
      "=================================================================\n",
      "Total params: 350,870\n",
      "Trainable params: 347,520\n",
      "Non-trainable params: 3,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 1.8533 - acc: 0.2188 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4714 - acc: 0.3438 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7798 - acc: 0.3125 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3819 - acc: 0.2188 - val_loss: 1.3865 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1329 - acc: 0.1562 - val_loss: 1.3865 - val_acc: 0.2500\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.9350 - acc: 0.0938 - val_loss: 1.3866 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5059 - acc: 0.3438 - val_loss: 1.3868 - val_acc: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6658 - acc: 0.2812 - val_loss: 1.3870 - val_acc: 0.2500\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8940 - acc: 0.2188 - val_loss: 1.3872 - val_acc: 0.2500\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4992 - acc: 0.2812 - val_loss: 1.3875 - val_acc: 0.2500\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5583 - acc: 0.4375 - val_loss: 1.3881 - val_acc: 0.2500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6498 - acc: 0.2500 - val_loss: 1.3886 - val_acc: 0.2500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3047 - acc: 0.3438 - val_loss: 1.3890 - val_acc: 0.2500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3031 - acc: 0.4062 - val_loss: 1.3900 - val_acc: 0.2500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6813 - acc: 0.2188 - val_loss: 1.3912 - val_acc: 0.2500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5269 - acc: 0.3125 - val_loss: 1.3923 - val_acc: 0.2500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.6864 - acc: 0.3125 - val_loss: 1.3935 - val_acc: 0.2500\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.7245 - acc: 0.1875 - val_loss: 1.3948 - val_acc: 0.2500\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4336 - acc: 0.1250 - val_loss: 1.3961 - val_acc: 0.2500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4475 - acc: 0.2812 - val_loss: 1.3979 - val_acc: 0.2500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4826 - acc: 0.3438 - val_loss: 1.3998 - val_acc: 0.2500\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3228 - acc: 0.4062 - val_loss: 1.4022 - val_acc: 0.2500\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4161 - acc: 0.2812 - val_loss: 1.4042 - val_acc: 0.2500\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4856 - acc: 0.2500 - val_loss: 1.4062 - val_acc: 0.2500\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2844 - acc: 0.4375 - val_loss: 1.4090 - val_acc: 0.2500\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3527 - acc: 0.3125 - val_loss: 1.4110 - val_acc: 0.2500\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4837 - acc: 0.3125 - val_loss: 1.4125 - val_acc: 0.2500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3311 - acc: 0.2188 - val_loss: 1.4117 - val_acc: 0.2500\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2735 - acc: 0.4062 - val_loss: 1.4138 - val_acc: 0.2500\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3687 - acc: 0.2500 - val_loss: 1.4166 - val_acc: 0.2500\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.5076 - acc: 0.4688 - val_loss: 1.4198 - val_acc: 0.2500\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2897 - acc: 0.4062 - val_loss: 1.4264 - val_acc: 0.2500\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3404 - acc: 0.4375 - val_loss: 1.4412 - val_acc: 0.2500\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4796 - acc: 0.4062 - val_loss: 1.4412 - val_acc: 0.2500\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4446 - acc: 0.3750 - val_loss: 1.4350 - val_acc: 0.2500\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4817 - acc: 0.3750 - val_loss: 1.4198 - val_acc: 0.2500\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5096 - acc: 0.3750 - val_loss: 1.4129 - val_acc: 0.2500\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3828 - acc: 0.2812 - val_loss: 1.3990 - val_acc: 0.2500\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.3711 - acc: 0.2812 - val_loss: 1.3813 - val_acc: 0.2500\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3442 - acc: 0.4062 - val_loss: 1.3670 - val_acc: 0.2500\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4269 - acc: 0.2812 - val_loss: 1.3514 - val_acc: 0.2500\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3076 - acc: 0.4375 - val_loss: 1.3403 - val_acc: 0.2500\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.4280 - acc: 0.2500 - val_loss: 1.3337 - val_acc: 0.2500\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 1.2619 - acc: 0.4688 - val_loss: 1.3305 - val_acc: 0.2500\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2586 - acc: 0.3438 - val_loss: 1.3347 - val_acc: 0.2500\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3453 - acc: 0.3125 - val_loss: 1.3561 - val_acc: 0.3750\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3016 - acc: 0.4375 - val_loss: 1.3539 - val_acc: 0.2500\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1841 - acc: 0.3750 - val_loss: 1.3543 - val_acc: 0.2500\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4089 - acc: 0.2500 - val_loss: 1.3508 - val_acc: 0.2500\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5485 - acc: 0.3750 - val_loss: 1.3272 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history_cnn2 = cnn2.fit(X_train_cnn2, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn2, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.275\n",
      "F1-score [0.41666667 0.         0.18181818 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.42        10\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       1.00      0.10      0.18        10\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.28        40\n",
      "   macro avg       0.32      0.28      0.15        40\n",
      "weighted avg       0.32      0.28      0.15        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\andre\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn2.predict(X_test_cnn2), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn3(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=8, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = build_cnn3(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 93, 16)            784       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 93, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 93, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 89, 32)            2592      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 89, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 89, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 87, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 87, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 87, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 87, 64)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 10,292\n",
      "Trainable params: 10,068\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 10s 318ms/step - loss: 1.4025 - acc: 0.2500 - val_loss: 1.3873 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3527 - acc: 0.2500 - val_loss: 1.3858 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3056 - acc: 0.3125 - val_loss: 1.3848 - val_acc: 0.2500\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2307 - acc: 0.5312 - val_loss: 1.3842 - val_acc: 0.2500\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2422 - acc: 0.5312 - val_loss: 1.3841 - val_acc: 0.3750\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1083 - acc: 0.7188 - val_loss: 1.3833 - val_acc: 0.2500\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0579 - acc: 0.7500 - val_loss: 1.3823 - val_acc: 0.2500\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0569 - acc: 0.6875 - val_loss: 1.3804 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9545 - acc: 0.7500 - val_loss: 1.3779 - val_acc: 0.6250\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9382 - acc: 0.7188 - val_loss: 1.3737 - val_acc: 0.6250\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8773 - acc: 0.7188 - val_loss: 1.3684 - val_acc: 0.7500\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7909 - acc: 0.8750 - val_loss: 1.3625 - val_acc: 0.7500\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.7722 - acc: 0.8438 - val_loss: 1.3541 - val_acc: 0.7500\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7105 - acc: 0.7500 - val_loss: 1.3452 - val_acc: 0.7500\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7139 - acc: 0.9062 - val_loss: 1.3305 - val_acc: 0.7500\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6500 - acc: 0.9375 - val_loss: 1.3118 - val_acc: 0.7500\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6135 - acc: 0.8438 - val_loss: 1.2972 - val_acc: 0.8750\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5040 - acc: 0.9062 - val_loss: 1.2749 - val_acc: 0.8750\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5303 - acc: 0.8438 - val_loss: 1.2507 - val_acc: 0.7500\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5654 - acc: 0.8438 - val_loss: 1.2203 - val_acc: 0.7500\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4614 - acc: 0.9375 - val_loss: 1.1861 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5587 - acc: 0.9375 - val_loss: 1.1588 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4340 - acc: 0.9688 - val_loss: 1.1329 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4433 - acc: 0.9375 - val_loss: 1.1105 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4167 - acc: 0.9062 - val_loss: 1.0884 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3664 - acc: 0.9688 - val_loss: 1.0607 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4699 - acc: 0.9062 - val_loss: 1.0471 - val_acc: 0.7500\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4464 - acc: 0.9375 - val_loss: 1.0241 - val_acc: 0.6250\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4896 - acc: 0.8750 - val_loss: 0.9853 - val_acc: 0.6250\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4751 - acc: 0.8750 - val_loss: 0.9391 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3669 - acc: 0.9062 - val_loss: 0.9024 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4498 - acc: 0.9062 - val_loss: 0.8763 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2997 - acc: 0.9688 - val_loss: 0.8382 - val_acc: 0.8750\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2874 - acc: 0.9688 - val_loss: 0.8109 - val_acc: 0.7500\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4851 - acc: 0.8750 - val_loss: 0.8139 - val_acc: 0.6250\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4407 - acc: 0.8438 - val_loss: 0.8491 - val_acc: 0.6250\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2989 - acc: 0.9688 - val_loss: 0.8183 - val_acc: 0.6250\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3533 - acc: 0.9062 - val_loss: 0.7837 - val_acc: 0.7500\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1842 - acc: 0.9688 - val_loss: 0.7675 - val_acc: 0.6250\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4932 - acc: 0.8438 - val_loss: 0.7664 - val_acc: 0.6250\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2156 - acc: 0.9688 - val_loss: 0.8302 - val_acc: 0.6250\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2467 - acc: 0.9688 - val_loss: 0.8311 - val_acc: 0.6250\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2895 - acc: 0.9375 - val_loss: 0.7758 - val_acc: 0.6250\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2866 - acc: 0.9688 - val_loss: 0.7250 - val_acc: 0.6250\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2384 - acc: 0.9688 - val_loss: 0.6984 - val_acc: 0.7500\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2154 - acc: 0.9688 - val_loss: 0.6840 - val_acc: 0.7500\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1594 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.7500\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1882 - acc: 0.9375 - val_loss: 0.6311 - val_acc: 0.7500\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1753 - acc: 0.9688 - val_loss: 0.6201 - val_acc: 0.8750\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1314 - acc: 1.0000 - val_loss: 0.5834 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history_cnn3 = cnn3.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.875\n",
      "F1-score [0.88888889 0.82352941 0.83333333 0.95238095]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "           2       0.71      1.00      0.83        10\n",
      "           3       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.91      0.88      0.87        40\n",
      "weighted avg       0.91      0.88      0.87        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn3.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyts.readthedocs.io/en/stable/generated/pyts.multivariate.classification.MultivariateClassifier.html#pyts.multivariate.classification.MultivariateClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
